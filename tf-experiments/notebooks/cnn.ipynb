{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "def_use_bnorm = True\n",
    "\n",
    "def_kernel_size = 5\n",
    "\n",
    "# normal sinus rhythm, atrial fibrillation (AF), an alternative rhythm, or is too noisy\n",
    "def_keep_prob = 0.5\n",
    "# Model Hyperparameters\n",
    "\n",
    "# FOR SCRIPTING\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('out_dims', '512, 1024', 'Size of feature map dimensions. Use comma separated integers [\"30, 10\"]')\n",
    "flags.DEFINE_string('kernel_sizes', '128, 64', 'Size of convolution kernels. Use comma separated integers [\"128, 64\"]')\n",
    "flags.DEFINE_float('keep_prob', def_keep_prob, 'Probability of keeping an activation value after the DROPOUT layer, during training [%f]'%def_keep_prob)\n",
    "flags.DEFINE_string('model_path', '/tmp/model', 'Logs will be saved to this directory')\n",
    "flags.DEFINE_bool('use_bnorm', def_use_bnorm, 'Use batch normalization if True, else use simply biases')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class model(object):\n",
    "    '''\n",
    "    Classify fixed length features, with weighted loss\n",
    "    classifier will return an object, whose main fields are tensorflow graph nodes.\n",
    "    \n",
    "    '''\n",
    "    def get_input(self):\n",
    "        # [batch_size, seq_len]\n",
    "        x = tf.placeholder(tf.float32, [None, None], name='input')\n",
    "        return x\n",
    "\n",
    "    def get_cnn(self, in_node, out_dims, kernel_sizes, keep_prob, use_bnorm=True):\n",
    "        '''\n",
    "        `out_dims`: a list of integers for the featuremap [out_dims1, out_dims2, ...]\n",
    "        `kernels_sizes`: a single integer or \n",
    "            a list of integers [kernel_size1, kernel_size2, ...] which must be the \n",
    "            same length as out_dims\n",
    "        '''\n",
    "        \n",
    "        if type(kernel_sizes) is not list:\n",
    "            kernel_sizes = [kernel_sizes] * len(out_dims)\n",
    "        \n",
    "        with tf.variable_scope('conv_module'):\n",
    "            h = in_node[..., None]\n",
    "            if use_bnorm:\n",
    "                biases_initializer = None\n",
    "                normalizer_fn = tf.contrib.layers.batch_norm\n",
    "            else:\n",
    "                biases_initializer = tf.zeros_initializer\n",
    "                normalizer_fn = None\n",
    "                \n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            \n",
    "            for dim, ker in zip(out_dims, kernel_sizes):\n",
    "                # does the same as 1d, but with convenience function\n",
    "                print('\\n', h)\n",
    "                h = tf.contrib.layers.conv2d(h, dim, ker, \n",
    "                                             normalizer_fn=normalizer_fn,\n",
    "                                             biases_initializer=biases_initializer)\n",
    "                \n",
    "                h = tf.nn.dropout(h, keep_prob)\n",
    "                print(h)\n",
    "        return h\n",
    "    \n",
    "    def get_name(self):\n",
    "        cnn_sizes = ['%dx%d'%(d, k) for d, k in \n",
    "            zip(self.out_dims, self.kernel_sizes)]\n",
    "        \n",
    "        name = '--cnn' + '-'.join(cnn_sizes)\n",
    "        name += '---' + time.strftime(\"%Y-%m-%d\")\n",
    "        return name\n",
    "    \n",
    "    def build_graph(self, model_name=None):\n",
    "        if not model_name:\n",
    "            model_name = self.get_name()\n",
    "        self.name = model_name\n",
    "        \n",
    "        self.keep_prob = tf.placeholder_with_default(self.def_keep_prob, [], 'keep_prob')\n",
    "        \n",
    "        if self.input is None:\n",
    "            self.input = self.get_input()\n",
    "        \n",
    "        self.output = self.get_cnn(\n",
    "            self.input, self.out_dims, self.kernel_sizes, self.keep_prob)\n",
    "    \n",
    "    def get_checkpoint_path(self):\n",
    "        return os.path.join(self.model_path, self.name)\n",
    "        \n",
    "    def __init__(self,\n",
    "            input=None,\n",
    "            out_dims=[int(s) for s in FLAGS.out_dims.split(',')],\n",
    "            kernel_sizes=[int(s) for s in FLAGS.kernel_sizes.split(',')],\n",
    "            keep_prob=FLAGS.keep_prob,\n",
    "            model_path=FLAGS.model_path,\n",
    "            model_name=None):\n",
    "        '''\n",
    "        Initializer default vales use tf.app.flags\n",
    "        returns an object, whose main fields are tensorflow graph nodes.\n",
    "        \n",
    "        fc_sizes: [int, [int...]] Size of fc layers connected to the last LSTM cell's output\n",
    "        keep_prob: float, Probability of keeping a value in DROPOUT layers\n",
    "        model_path: str, path/to/model/dir\n",
    "        '''\n",
    "        self.input = input\n",
    "        self.out_dims = out_dims\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        \n",
    "        if len(kernel_sizes) == 1:\n",
    "            kernel_sizes = [kernel_sizes] * len(out_dims)\n",
    "        \n",
    "        self.def_keep_prob = keep_prob\n",
    "        self.model_path = model_path\n",
    "        with tf.variable_scope('CNN'):\n",
    "            self.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tensor(\"CNN_2/conv_module/strided_slice:0\", shape=(?, ?, 1), dtype=float32)\n",
      "Tensor(\"CNN_2/conv_module/dropout/mul:0\", shape=(?, ?, 512), dtype=float32)\n",
      "\n",
      " Tensor(\"CNN_2/conv_module/dropout/mul:0\", shape=(?, ?, 512), dtype=float32)\n",
      "Tensor(\"CNN_2/conv_module/dropout_1/mul:0\", shape=(?, ?, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'CNN_2/conv_module/dropout_1/mul:0' shape=(?, ?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 10, 1024)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_len = 10\n",
    "res = c.output.eval({c.input:np.random.randn(batch_size, seq_len)})\n",
    "print(res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
