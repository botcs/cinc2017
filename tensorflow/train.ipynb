{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import model.cnn as cnn\n",
    "import model.rnn as rnn\n",
    "import model.classifier as classifier\n",
    "\n",
    "import data.ops\n",
    "import time\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN--cnn10x360-10x360-10x360-10x360-10x360\n",
      "Tensor(\"CNN/Conv1/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv2/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv3/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv4/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv5/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "\n",
      "RNN--rnn--steps100--sizes30\n",
      "LSTMStateTuple(c=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_2:0' shape=(?, 30) dtype=float32>, h=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_3:0' shape=(?, 30) dtype=float32>)\n",
      "\n",
      "FC--fc100-10\n",
      "Tensor(\"classifier/hidden_layer0/fully_connected/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"classifier/hidden_layer1/fully_connected/Relu:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"classifier/logits/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"classifier/predictions:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = tf.placeholder_with_default(64, [], name='batch_size')\n",
    "    \n",
    "cnn_params = {\n",
    "    'out_dims' : [10, 10, 10, 10, 10],\n",
    "    'kernel_sizes' : 360,\n",
    "    'pool_sizes' : 2\n",
    "}\n",
    "rnn_params = {\n",
    "    'rnn_sizes' : [30],\n",
    "    'time_steps' : 100\n",
    "}\n",
    "fc_params = {\n",
    "    'fc_sizes' : [100, 10]\n",
    "}\n",
    "\n",
    "input_op, seq_len, label = data.ops.get_batch_producer(\n",
    "    batch_size=batch_size, path='./data/train.TFRecord')\n",
    "\n",
    "c = cnn.get_output(seq_len=seq_len, input_op=input_op, **cnn_params)\n",
    "r = rnn.get_model(batch_size=batch_size, seq_len=seq_len, input_op=c, **rnn_params)\n",
    "logits, pred = classifier.get_logits_and_pred(input_op=r.last_output, **fc_params)\n",
    "\n",
    "model_name = 'largeCNN-handloss'\n",
    "MODEL_PATH = '/tmp/model/' + model_name # + c.name + r.name + classifier.name\n",
    "MODEL_EXISTS = os.path.exists(MODEL_PATH)\n",
    "if MODEL_EXISTS:\n",
    "    print('Model directory is not empty, removing old files')\n",
    "    shutil.rmtree(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Time measure\n",
    "\n",
    "convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def measure_time(op, feed_dict={}, n_times=10):\n",
    "    with tf.Session() as sess:\n",
    "        print('Sess started')\n",
    "        coord = tf.train.Coordinator()\n",
    "        tf.global_variables_initializer().run()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        print('Evaluating')\n",
    "        for _ in range(n_times):\n",
    "            t = time.time()\n",
    "            fetch = sess.run(op, feed_dict)\n",
    "            print(fetch, 'Eval time:', time.time() - t)\n",
    "            \n",
    "        print('Closing threads')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "        return fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "## **Confusion matrix**\n",
    "\n",
    "## **Accuracy operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('evaluation'):\n",
    "    with tf.name_scope('one_hot_encoding'):\n",
    "        y_oh = tf.cast(tf.equal(\n",
    "            logits, tf.reduce_max(logits, axis=1)[:, None]), tf.float32)[..., None]\n",
    "\n",
    "        label_oh = tf.one_hot(label, depth=4)[..., None]\n",
    "    with tf.name_scope('confusion_matrix'):\n",
    "        conf_op = tf.reduce_sum(tf.transpose(y_oh, perm=[0, 2, 1]) * label_oh,\n",
    "            axis=0, name='result')\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        y_tot = tf.reduce_sum(conf_op, axis=0, name='label_class_sum')\n",
    "        label_tot = tf.reduce_sum(conf_op, axis=1, name='pred_class_sum')\n",
    "        correct_op = tf.diag_part(conf_op, name='correct_class_sum')\n",
    "        eps = tf.constant([1e-10] * 4, name='eps')\n",
    "        acc = tf.reduce_mean(2*correct_op / (y_tot + label_tot + eps), name='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sparse, weighted softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5154,  771, 2557,   46]),\n",
       " <tf.Tensor 'loss/weight_selector:0' shape=(?,) dtype=float32>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_hist = np.load('./data/class_hist.npy')\n",
    "with tf.name_scope('loss'):\n",
    "    weight = tf.constant([.1, 1, .2, 3])\n",
    "    #weight = tf.constant(1 - np.sqrt(class_hist/class_hist.sum()), name='weights')\n",
    "    weight = tf.gather(weight, label, name='weight_selector')\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(label, logits, weight, scope='weighted_loss')\n",
    "    unweighted_loss = tf.losses.sparse_softmax_cross_entropy(label, logits, scope='unweighted_loss')\n",
    "class_hist, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    learning_rate = tf.Variable(initial_value=.05, trainable=False, name='learning_rate')\n",
    "    global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "    grad_clip = tf.Variable(initial_value=3., trainable=False, name='grad_clip')\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    with tf.name_scope('gradient_clipping'):\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -grad_clip, grad_clip), var) \n",
    "                      for grad, var in gvs]\n",
    "        \n",
    "    opt = optimizer.apply_gradients(capped_gvs, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter(MODEL_PATH, graph=tf.get_default_graph())\n",
    "sum_ops = []\n",
    "for v in tf.trainable_variables():\n",
    "    sum_ops.append(tf.summary.histogram(v.name[:-2], v))\n",
    "    sum_ops.append(tf.summary.histogram('gradients/'+v.name[:-2], tf.gradients(loss, v)))\n",
    "\n",
    "sum_ops.append(tf.summary.scalar('weighted_loss', loss))\n",
    "sum_ops.append(tf.summary.scalar('unweighted_loss', unweighted_loss))\n",
    "sum_ops.append(tf.summary.scalar('accuracy', acc))\n",
    "sum_ops.append(tf.summary.image('confusion_matrix', conf_op[None, ..., None], max_outputs=10))\n",
    "summaries = tf.summary.merge(sum_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=1)\n",
    "#with open('test.txt', 'w') as f:\n",
    "    #metagraph = saver.export_meta_graph(as_text=True)\n",
    "    #f.write(str(metagraph.ListFields()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sess started\n",
      "Initializing model\n",
      "Training\n",
      "1/4999 time:4.857495 loss:0.286065 acc:0.148516\n",
      "2/4999 time:3.684704 loss:0.370896 acc:0.188148\n",
      "3/4999 time:1.284986 loss:0.285891 acc:0.238073\n",
      "4/4999 time:1.331241 loss:0.356416 acc:0.224567\n",
      "5/4999 time:1.270860 loss:0.244619 acc:0.138799\n",
      "6/4999 time:1.313504 loss:0.221535 acc:0.039447\n",
      "7/4999 time:1.312521 loss:0.297948 acc:0.079837\n",
      "8/4999 time:1.309821 loss:0.264745 acc:0.054894\n",
      "9/4999 time:1.275188 loss:0.265898 acc:0.058290\n",
      "10/4999 time:1.303985 loss:0.573987 acc:0.183614\n",
      "Evaluating summaries...\n",
      "11/4999 time:1.381268 loss:0.239877 acc:0.096300\n",
      "12/4999 time:1.404033 loss:0.228286 acc:0.048856\n",
      "13/4999 time:1.339311 loss:0.275151 acc:0.059989\n",
      "14/4999 time:1.281811 loss:0.263105 acc:0.109855\n",
      "15/4999 time:1.325436 loss:0.445003 acc:0.105072\n",
      "16/4999 time:1.393899 loss:0.397016 acc:0.086350\n",
      "17/4999 time:1.358587 loss:0.236394 acc:0.034441\n",
      "18/4999 time:1.319567 loss:0.251169 acc:0.056636\n",
      "19/4999 time:3.633179 loss:0.361393 acc:0.049296\n",
      "20/4999 time:1.320498 loss:0.503325 acc:0.073333\n",
      "Evaluating summaries...\n",
      "21/4999 time:1.304788 loss:0.246157 acc:0.055978\n",
      "22/4999 time:1.321292 loss:0.454398 acc:0.036232\n",
      "23/4999 time:1.299055 loss:0.406258 acc:0.036232\n",
      "24/4999 time:1.312343 loss:0.260403 acc:0.042857\n",
      "25/4999 time:1.325464 loss:0.347407 acc:0.042857\n",
      "26/4999 time:1.291970 loss:0.446118 acc:0.049296\n",
      "27/4999 time:1.340728 loss:0.362363 acc:0.049296\n",
      "28/4999 time:1.336322 loss:0.218509 acc:0.022388\n",
      "29/4999 time:3.474040 loss:0.248763 acc:0.036232\n",
      "30/4999 time:3.614296 loss:0.229368 acc:0.059738\n",
      "Evaluating summaries...\n",
      "31/4999 time:1.326140 loss:0.430434 acc:0.133929\n",
      "32/4999 time:1.368028 loss:0.243602 acc:0.065341\n",
      "33/4999 time:1.302015 loss:0.246693 acc:0.109165\n",
      "34/4999 time:1.328401 loss:0.260928 acc:0.079487\n",
      "35/4999 time:1.393480 loss:0.383327 acc:0.050725\n",
      "36/4999 time:1.381423 loss:0.319865 acc:0.119919\n",
      "37/4999 time:1.378721 loss:0.308992 acc:0.084416\n",
      "38/4999 time:1.329271 loss:0.208358 acc:0.029412\n",
      "39/4999 time:1.337606 loss:0.239693 acc:0.036232\n",
      "40/4999 time:1.324769 loss:0.263936 acc:0.042857\n",
      "Evaluating summaries...\n",
      "41/4999 time:3.604711 loss:0.376006 acc:0.049296\n",
      "42/4999 time:1.301162 loss:0.297389 acc:0.073333\n",
      "43/4999 time:1.327944 loss:0.231966 acc:0.029412\n",
      "44/4999 time:1.329243 loss:0.237113 acc:0.055556\n",
      "45/4999 time:1.322488 loss:0.240556 acc:0.044118\n",
      "46/4999 time:1.329239 loss:0.241955 acc:0.095584\n",
      "47/4999 time:1.283802 loss:0.262599 acc:0.125678\n",
      "48/4999 time:1.338751 loss:0.236483 acc:0.131181\n",
      "49/4999 time:1.363283 loss:0.265622 acc:0.155503\n",
      "50/4999 time:1.331378 loss:0.225198 acc:0.078190\n",
      "Evaluating summaries...\n",
      "Saving model...\n",
      "/tmp/model/largeCNN-handloss-50\n",
      "51/4999 time:1.313424 loss:0.359260 acc:0.042857\n",
      "52/4999 time:1.320934 loss:0.259188 acc:0.055556\n",
      "53/4999 time:1.341166 loss:0.246923 acc:0.049296\n",
      "54/4999 time:1.329777 loss:0.417018 acc:0.015152\n",
      "55/4999 time:3.450698 loss:0.260124 acc:0.042857\n",
      "56/4999 time:1.327505 loss:0.227654 acc:0.036232\n",
      "57/4999 time:1.370869 loss:0.215989 acc:0.029412\n",
      "58/4999 time:1.311970 loss:0.249180 acc:0.037879\n",
      "59/4999 time:1.312154 loss:0.326600 acc:0.038065\n",
      "60/4999 time:1.315671 loss:0.412392 acc:0.059295\n",
      "Evaluating summaries...\n",
      "61/4999 time:1.321743 loss:0.336878 acc:0.050125\n",
      "62/4999 time:1.325934 loss:0.202694 acc:0.083221\n",
      "63/4999 time:1.293680 loss:0.212256 acc:0.069658\n",
      "64/4999 time:3.433187 loss:0.324906 acc:0.070622\n",
      "65/4999 time:1.320542 loss:0.317127 acc:0.132650\n",
      "66/4999 time:1.336314 loss:0.273834 acc:0.105195\n",
      "67/4999 time:1.343978 loss:0.209289 acc:0.054708\n",
      "68/4999 time:1.300973 loss:0.418013 acc:0.137731\n",
      "69/4999 time:1.301318 loss:0.181940 acc:0.128750\n",
      "70/4999 time:1.297682 loss:0.353503 acc:0.206044\n",
      "Evaluating summaries...\n",
      "71/4999 time:1.347064 loss:0.328671 acc:0.191176\n",
      "72/4999 time:3.569906 loss:0.258058 acc:0.170103\n",
      "73/4999 time:1.320488 loss:0.228339 acc:0.189320\n",
      "74/4999 time:1.352387 loss:0.230406 acc:0.189320\n",
      "75/4999 time:1.307073 loss:0.295831 acc:0.180000\n",
      "76/4999 time:1.324803 loss:0.298817 acc:0.176768\n",
      "77/4999 time:1.312064 loss:0.284911 acc:0.192308\n",
      "78/4999 time:1.328247 loss:0.223593 acc:0.198113\n",
      "79/4999 time:3.464012 loss:0.289869 acc:0.186275\n",
      "80/4999 time:2.576011 loss:0.239865 acc:0.036232\n",
      "Evaluating summaries...\n",
      "81/4999 time:3.480320 loss:0.176640 acc:0.000000\n",
      "82/4999 time:3.613793 loss:0.160219 acc:0.023810\n",
      "83/4999 time:2.646785 loss:0.168462 acc:0.000000\n",
      "84/4999 time:3.533336 loss:0.163662 acc:0.129412\n",
      "85/4999 time:3.612052 loss:0.163904 acc:0.142045\n",
      "86/4999 time:3.161499 loss:0.180465 acc:0.183168\n",
      "87/4999 time:3.650701 loss:0.153320 acc:0.127907\n",
      "88/4999 time:3.496450 loss:0.151721 acc:0.132184\n",
      "89/4999 time:3.451827 loss:0.145851 acc:0.123529\n",
      "90/4999 time:1.313222 loss:0.158492 acc:0.173469\n",
      "Evaluating summaries...\n",
      "91/4999 time:1.319044 loss:0.228147 acc:0.127907\n",
      "92/4999 time:1.339717 loss:0.348722 acc:0.123529\n",
      "93/4999 time:1.329626 loss:0.273361 acc:0.114458\n",
      "94/4999 time:1.320497 loss:0.272790 acc:0.118155\n",
      "95/4999 time:1.282033 loss:0.322895 acc:0.104938\n",
      "96/4999 time:1.309103 loss:0.390251 acc:0.094937\n",
      "97/4999 time:1.276373 loss:0.587433 acc:0.119048\n",
      "98/4999 time:2.575335 loss:0.246846 acc:0.114458\n",
      "99/4999 time:1.327376 loss:0.372420 acc:0.104938\n",
      "100/4999 time:1.358993 loss:0.360301 acc:0.089744\n",
      "Evaluating summaries...\n",
      "Saving model...\n",
      "/tmp/model/largeCNN-handloss-100\n",
      "101/4999 time:1.374797 loss:0.314847 acc:0.104938\n",
      "102/4999 time:3.614030 loss:0.652373 acc:0.100000\n",
      "103/4999 time:1.347975 loss:0.267602 acc:0.109756\n",
      "104/4999 time:1.276181 loss:0.382140 acc:0.127907\n",
      "105/4999 time:1.284987 loss:0.474139 acc:0.036232\n",
      "106/4999 time:1.305265 loss:0.221712 acc:0.036232\n",
      "107/4999 time:1.382792 loss:0.241090 acc:0.043478\n",
      "108/4999 time:1.359272 loss:0.225256 acc:0.029412\n",
      "109/4999 time:1.322241 loss:0.267617 acc:0.055556\n",
      "110/4999 time:1.315256 loss:0.280091 acc:0.061644\n",
      "Evaluating summaries...\n",
      "111/4999 time:1.313420 loss:0.388576 acc:0.049296\n",
      "112/4999 time:3.234165 loss:0.281072 acc:0.067568\n",
      "113/4999 time:1.389186 loss:0.287905 acc:0.061644\n",
      "114/4999 time:1.306109 loss:0.263486 acc:0.042857\n",
      "115/4999 time:1.325179 loss:0.559311 acc:0.078947\n",
      "116/4999 time:1.365481 loss:0.355314 acc:0.036232\n",
      "117/4999 time:1.290033 loss:0.384953 acc:0.055556\n",
      "118/4999 time:1.312958 loss:0.258317 acc:0.042857\n",
      "119/4999 time:1.335014 loss:0.272461 acc:0.049296\n",
      "120/4999 time:1.300332 loss:0.221148 acc:0.029412\n",
      "Evaluating summaries...\n",
      "121/4999 time:1.346185 loss:0.265438 acc:0.042857\n",
      "122/4999 time:1.331616 loss:0.244852 acc:0.061123\n",
      "123/4999 time:1.329316 loss:0.277316 acc:0.086025\n",
      "124/4999 time:1.325914 loss:0.270133 acc:0.043478\n",
      "125/4999 time:1.320207 loss:0.365447 acc:0.037313\n",
      "126/4999 time:1.304440 loss:0.245791 acc:0.036765\n",
      "127/4999 time:1.385145 loss:0.207566 acc:0.007812\n",
      "128/4999 time:1.319294 loss:0.244047 acc:0.070433\n",
      "129/4999 time:1.350028 loss:0.251195 acc:0.050000\n",
      "130/4999 time:1.371251 loss:0.257710 acc:0.036232\n",
      "Evaluating summaries...\n",
      "131/4999 time:1.405817 loss:0.259030 acc:0.049296\n",
      "132/4999 time:1.425982 loss:0.285283 acc:0.061644\n",
      "133/4999 time:1.335776 loss:0.216517 acc:0.022727\n",
      "134/4999 time:1.335977 loss:0.226239 acc:0.036232\n",
      "135/4999 time:1.342510 loss:0.261399 acc:0.042857\n",
      "136/4999 time:1.388284 loss:0.378325 acc:0.050000\n",
      "137/4999 time:1.316879 loss:0.403615 acc:0.068493\n",
      "138/4999 time:1.352507 loss:0.255722 acc:0.042857\n",
      "139/4999 time:1.324422 loss:0.235195 acc:0.059053\n",
      "140/4999 time:1.297796 loss:0.425382 acc:0.050000\n",
      "Evaluating summaries...\n",
      "141/4999 time:1.621057 loss:0.260316 acc:0.055556\n",
      "142/4999 time:1.286706 loss:0.245832 acc:0.049296\n",
      "143/4999 time:1.351131 loss:0.372275 acc:0.036232\n",
      "144/4999 time:1.339203 loss:0.361648 acc:0.029412\n",
      "145/4999 time:1.296722 loss:0.266641 acc:0.049296\n",
      "146/4999 time:1.310100 loss:0.353649 acc:0.036232\n",
      "147/4999 time:1.339815 loss:0.489196 acc:0.042857\n",
      "148/4999 time:1.351794 loss:0.391977 acc:0.055556\n",
      "149/4999 time:1.316220 loss:0.223521 acc:0.036232\n",
      "150/4999 time:1.364707 loss:0.232578 acc:0.036232\n",
      "Evaluating summaries...\n",
      "Saving model...\n",
      "/tmp/model/largeCNN-handloss-150\n",
      "151/4999 time:1.573390 loss:0.253053 acc:0.049296\n",
      "152/4999 time:1.288317 loss:0.251099 acc:0.049296\n",
      "153/4999 time:1.352543 loss:0.370752 acc:0.042857\n",
      "154/4999 time:1.339764 loss:0.211293 acc:0.022388\n",
      "155/4999 time:1.318053 loss:0.266992 acc:0.049296\n",
      "156/4999 time:1.312693 loss:0.377618 acc:0.049296\n",
      "157/4999 time:1.300683 loss:0.339930 acc:0.089744\n",
      "158/4999 time:1.306774 loss:0.286935 acc:0.073333\n",
      "159/4999 time:1.325619 loss:0.228784 acc:0.042857\n",
      "160/4999 time:1.313534 loss:0.219276 acc:0.036232\n",
      "Evaluating summaries...\n",
      "161/4999 time:1.572923 loss:0.474383 acc:0.042857\n",
      "162/4999 time:1.371239 loss:0.380511 acc:0.049296\n",
      "163/4999 time:1.333922 loss:0.290557 acc:0.067568\n",
      "164/4999 time:1.289485 loss:0.256425 acc:0.049296\n",
      "165/4999 time:1.302686 loss:0.250764 acc:0.049296\n",
      "166/4999 time:1.356922 loss:0.233529 acc:0.036232\n",
      "167/4999 time:1.318297 loss:0.232794 acc:0.042857\n",
      "168/4999 time:1.332748 loss:0.268037 acc:0.061644\n",
      "169/4999 time:1.332766 loss:0.233956 acc:0.029412\n",
      "170/4999 time:1.293159 loss:0.242873 acc:0.042857\n",
      "Evaluating summaries...\n",
      "171/4999 time:1.371329 loss:0.270940 acc:0.067568\n",
      "172/4999 time:1.259934 loss:0.360626 acc:0.036232\n",
      "173/4999 time:1.289244 loss:0.275774 acc:0.055556\n",
      "174/4999 time:1.380100 loss:0.250277 acc:0.055556\n",
      "175/4999 time:1.319522 loss:0.345662 acc:0.022388\n",
      "176/4999 time:1.274152 loss:0.228491 acc:0.015152\n",
      "177/4999 time:1.314764 loss:0.269602 acc:0.055556\n",
      "178/4999 time:1.308146 loss:0.208412 acc:0.022388\n",
      "179/4999 time:1.278696 loss:0.230536 acc:0.036232\n",
      "180/4999 time:1.322798 loss:0.350881 acc:0.036232\n",
      "Evaluating summaries...\n",
      "181/4999 time:1.279435 loss:0.448353 acc:0.007692\n",
      "182/4999 time:1.332116 loss:0.373860 acc:0.036232\n",
      "183/4999 time:1.316349 loss:0.311108 acc:0.007692\n",
      "184/4999 time:1.293200 loss:0.226079 acc:0.036232\n",
      "185/4999 time:1.343482 loss:0.329708 acc:0.022388\n",
      "186/4999 time:1.328954 loss:0.342961 acc:0.029412\n",
      "187/4999 time:1.309890 loss:0.241257 acc:0.036232\n",
      "188/4999 time:1.299963 loss:0.219513 acc:0.036232\n",
      "189/4999 time:1.292433 loss:0.332048 acc:0.029412\n",
      "190/4999 time:1.288577 loss:0.309310 acc:0.015152\n",
      "Evaluating summaries...\n",
      "191/4999 time:1.380904 loss:0.279929 acc:0.055556\n",
      "192/4999 time:1.321893 loss:0.349345 acc:0.036232\n",
      "193/4999 time:1.332909 loss:0.201108 acc:0.015152\n",
      "194/4999 time:1.317098 loss:0.249956 acc:0.036232\n",
      "195/4999 time:1.370878 loss:0.230260 acc:0.036232\n",
      "196/4999 time:1.308792 loss:0.241375 acc:0.036232\n",
      "197/4999 time:1.307241 loss:0.347491 acc:0.176768\n",
      "198/4999 time:1.278785 loss:0.174452 acc:0.000000\n",
      "199/4999 time:1.284133 loss:0.312068 acc:0.022388\n",
      "200/4999 time:1.330342 loss:0.269814 acc:0.049296\n",
      "Evaluating summaries...\n",
      "Saving model...\n",
      "/tmp/model/largeCNN-handloss-200\n",
      "201/4999 time:1.313034 loss:0.216012 acc:0.022388\n",
      "202/4999 time:1.558301 loss:0.172334 acc:0.000000\n",
      "203/4999 time:1.302222 loss:0.163885 acc:0.000000\n",
      "204/4999 time:1.331486 loss:0.164116 acc:0.140449\n",
      "205/4999 time:1.371281 loss:0.157123 acc:0.127907\n",
      "206/4999 time:1.251860 loss:0.159775 acc:0.140449\n",
      "207/4999 time:1.312082 loss:0.170913 acc:0.173469\n"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 5000\n",
    "with tf.Session() as sess:\n",
    "    print('Sess started')\n",
    "    \n",
    "    print('Initializing model')\n",
    "    tf.global_variables_initializer().run()\n",
    "        \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    print('Training')\n",
    "    for i in range(TRAIN_STEPS):\n",
    "        t = time.time()\n",
    "        fetch = sess.run([opt, loss, acc, global_step])\n",
    "        step = fetch[-1]\n",
    "        print('%d/%d'%(step, TRAIN_STEPS), \n",
    "              'time:%f'%(time.time()-t), \n",
    "              'loss:%f'%fetch[1],\n",
    "              'acc:%f'%fetch[2]\n",
    "              )\n",
    "        if step % 10 == 0:\n",
    "            print('Evaluating summaries...')\n",
    "            train_writer.add_summary(summaries.eval(), global_step=fetch[-1])\n",
    "        if step % 50 == 0:\n",
    "            print('Saving model...')\n",
    "            print(saver.save(sess, MODEL_PATH, global_step=fetch[-1]))\n",
    "    \n",
    "    print('Ending, closing producer threads')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
