{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import model.cnn as cnn\n",
    "import model.rnn as rnn\n",
    "import model.classifier as classifier\n",
    "\n",
    "import data.ops\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN--cnn10x32\n",
      "Tensor(\"CNN/conv_module/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "\n",
      "RNN--rnn--steps100--sizes10\n",
      "LSTMStateTuple(c=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_2:0' shape=(?, 10) dtype=float32>, h=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_3:0' shape=(?, 10) dtype=float32>)\n",
      "\n",
      "FC--fc\n",
      "Tensor(\"classifier/fully_connected/logits/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"classifier/pred:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = tf.placeholder_with_default(32, [])\n",
    "input_op, seq_len, label = data.ops.get_batch_producer(\n",
    "    batch_size=batch_size, path='./data/train.TFRecord')\n",
    "\n",
    "cnn_params = {\n",
    "    'out_dims' : [10],\n",
    "    'kernel_sizes' : 32,\n",
    "    'pool_sizes' : 10\n",
    "}\n",
    "rnn_params = {\n",
    "    'rnn_sizes' : [10],\n",
    "    'time_steps' : 100\n",
    "}\n",
    "fc_params = {\n",
    "    'fc_sizes' : []\n",
    "}\n",
    "\n",
    "c = cnn.get_output(seq_len=seq_len, input_op=input_op, **cnn_params)\n",
    "r = rnn.get_model(batch_size=batch_size, seq_len=seq_len, input_op=c, **rnn_params)\n",
    "logits, pred = classifier.get_logits_and_pred(input_op=r.last_output, **fc_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time measure\n",
    "\n",
    "convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_time(op, feed_dict={}, n_times=10):\n",
    "    with tf.Session() as sess:\n",
    "        print('Sess started')\n",
    "        coord = tf.train.Coordinator()\n",
    "        tf.global_variables_initializer().run()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        init_state = sess.run(r.zero_state)\n",
    "        rnn_feed = {r.init_state : init_state}\n",
    "        feed_dict.update(rnn_feed)\n",
    "        print('Evaluating')\n",
    "        for _ in range(n_times):\n",
    "            t = time.time()\n",
    "            test_output = sess.run(op, feed_dict)\n",
    "            print(test_output, 'Eval time:', time.time() - t)\n",
    "            \n",
    "        print('Closing threads')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "        return test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## **Confusion matrix**\n",
    "\n",
    "## **Accuracy operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder_with_default(input=logits, shape=[None, 4])\n",
    "x_oh = tf.cast(tf.equal(x, tf.reduce_max(x, axis=1)[:, None]), tf.float32)[..., None]\n",
    "#x_oh = tf.equal(x, tf.reduce_max(x, axis=1)[:, None])[..., None]\n",
    "y = tf.placeholder_with_default(input=label, shape=[None])\n",
    "y_oh = tf.one_hot(y, depth=4)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"confusion_matrix:0\", shape=(4, 4), dtype=float32)\n",
      "Tensor(\"accuracy:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conf_op = tf.reduce_sum(tf.transpose(x_oh, perm=[0, 2, 1]) * y_oh,\n",
    "    axis=0, name='confusion_matrix')\n",
    "\n",
    "print(conf_op)\n",
    "x_tot = tf.reduce_sum(conf_op, axis=0)\n",
    "y_tot = tf.reduce_sum(conf_op, axis=1)\n",
    "correct_op = tf.diag_part(conf_op)\n",
    "eps = [1e-10] * 4\n",
    "acc_op = tf.reduce_mean(2*correct_op / (x_tot + y_tot + eps), name='accuracy')\n",
    "print(acc_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[0.16666667]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(conf_op.eval({x:[[.1, .2, .3, .4], [.1, .2, .3, .4]], y:[3, 0]}))\n",
    "    print(sess.run([acc_op], {x:[[.1, .2, .3, .4], [.1, .2, .3, .4]], y:[3, 0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sess started\n",
      "Evaluating\n",
      "0.109756 Eval time: 2.7907462120056152\n",
      "0.127002 Eval time: 0.49909067153930664\n",
      "0.0681818 Eval time: 0.5650448799133301\n",
      "Closing threads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06818182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_time(acc_op, n_times=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sparse, weighted softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5154,  771, 2557,   46]),\n",
       " <tf.Tensor 'weight:0' shape=(?,) dtype=float64>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_hist = np.load('./data/class_hist.npy')\n",
    "weight = tf.gather(tf.constant(1 - np.sqrt(class_hist/class_hist.sum())), label, name='weight')\n",
    "\n",
    "class_hist, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.sparse_softmax_cross_entropy(label, logits, weight)\n",
    "unweighted_loss = tf.losses.sparse_softmax_cross_entropy(label, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sess started\n",
      "Evaluating\n",
      "[0.49806154, 1.3993574] Eval time: 0.6323027610778809\n",
      "[0.41979244, 1.3813533] Eval time: 0.4587879180908203\n",
      "[0.49946821, 1.3793981] Eval time: 0.453294038772583\n",
      "[0.52182496, 1.3881139] Eval time: 2.2066774368286133\n",
      "[0.49599224, 1.3609421] Eval time: 0.4102365970611572\n",
      "[0.40283754, 1.3684117] Eval time: 0.5056233406066895\n",
      "[0.51788628, 1.395148] Eval time: 0.4189016819000244\n",
      "[0.44691628, 1.3935302] Eval time: 0.4730651378631592\n",
      "[0.45892927, 1.4054298] Eval time: 0.45441389083862305\n",
      "[0.42116034, 1.3878207] Eval time: 0.4829261302947998\n",
      "Closing threads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42116034, 1.3878207]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_time([loss, unweighted_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.Variable(initial_value=.05, trainable=False, name='learning_rate')\n",
    "global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "grad_clip = tf.Variable(initial_value=3., trainable=False, name='grad_clip')\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    with tf.name_scope('gradient_clipping'):\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -grad_clip, grad_clip), var) \n",
    "                      for grad, var in gvs]\n",
    "        \n",
    "    opt = optimizer.apply_gradients(capped_gvs, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sess started\n",
      "Evaluating\n",
      "[0.48074871, 1.4008858, 0.055555556, None] Eval time: 3.2106688022613525\n",
      "[0.38809419, 1.2457941, 0.21938775, None] Eval time: 1.535161018371582\n",
      "[0.42092943, 1.1100838, 0.17897727, None] Eval time: 1.5493321418762207\n",
      "[0.43511623, 1.1471479, 0.12790698, None] Eval time: 2.9214348793029785\n",
      "[0.42858675, 1.1850848, 0.1097561, None] Eval time: 1.5219848155975342\n",
      "[0.31411856, 1.0774897, 0.1, None] Eval time: 1.5246484279632568\n",
      "[0.51634991, 1.1116172, 0.16666667, None] Eval time: 1.5631794929504395\n",
      "[0.33072644, 0.93621349, 0.2090909, None] Eval time: 1.5349981784820557\n",
      "[0.33033174, 0.91691887, 0.1981132, None] Eval time: 1.5619332790374756\n",
      "[0.29583973, 0.86346889, 0.2037037, None] Eval time: 1.4362695217132568\n",
      "Closing threads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29583973, 0.86346889, 0.2037037, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_time([loss, unweighted_loss, acc_op, opt], n_times=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
