{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import model.cnn as cnn\n",
    "import model.rnn as rnn\n",
    "import model.classifier as classifier\n",
    "\n",
    "import data.ops\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN--cnn10x32-10x32-10x32\n",
      "Tensor(\"CNN/Conv1/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv2/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "Tensor(\"CNN/Conv3/MaxPool2D/MaxPool:0\", shape=(?, ?, 1, 10), dtype=float32)\n",
      "\n",
      "RNN--rnn--steps100--sizes10\n",
      "LSTMStateTuple(c=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_2:0' shape=(?, 10) dtype=float32>, h=<tf.Tensor 'RNN/LSTM/dynamic_wrapper/rnn/while/Exit_3:0' shape=(?, 10) dtype=float32>)\n",
      "\n",
      "FC--fc30-20-10\n",
      "Tensor(\"classifier/hidden_layer0/fully_connected/Relu:0\", shape=(?, 30), dtype=float32)\n",
      "Tensor(\"classifier/hidden_layer1/fully_connected/Relu:0\", shape=(?, 20), dtype=float32)\n",
      "Tensor(\"classifier/hidden_layer2/fully_connected/Relu:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"classifier/logits/BiasAdd:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"classifier/predictions:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = tf.placeholder_with_default(32, [], name='batch_size')    \n",
    "cnn_params = {\n",
    "    'out_dims' : [10, 10, 10],\n",
    "    'kernel_sizes' : 32,\n",
    "    'pool_sizes' : 2\n",
    "}\n",
    "rnn_params = {\n",
    "    'rnn_sizes' : [10],\n",
    "    'time_steps' : 100\n",
    "}\n",
    "fc_params = {\n",
    "    'fc_sizes' : [30, 20, 10]\n",
    "}\n",
    "\n",
    "input_op, seq_len, label = data.ops.get_batch_producer(\n",
    "    batch_size=batch_size, path='./data/train.TFRecord')\n",
    "\n",
    "c = cnn.get_output(seq_len=seq_len, input_op=input_op, **cnn_params)\n",
    "r = rnn.get_model(batch_size=batch_size, seq_len=seq_len, input_op=c, **rnn_params)\n",
    "logits, pred = classifier.get_logits_and_pred(input_op=r.last_output, **fc_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Time measure\n",
    "\n",
    "convenience function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def measure_time(op, feed_dict={}, n_times=10):\n",
    "    with tf.Session() as sess:\n",
    "        print('Sess started')\n",
    "        coord = tf.train.Coordinator()\n",
    "        tf.global_variables_initializer().run()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "        init_state = sess.run(r.zero_state)\n",
    "        rnn_feed = {r.init_state : init_state}\n",
    "        feed_dict.update(rnn_feed)\n",
    "        print('Evaluating')\n",
    "        for _ in range(n_times):\n",
    "            t = time.time()\n",
    "            test_output = sess.run(op, feed_dict)\n",
    "            print(test_output, 'Eval time:', time.time() - t)\n",
    "            \n",
    "        print('Closing threads')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "        return test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "## **Confusion matrix**\n",
    "\n",
    "## **Accuracy operator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('evaluation'):\n",
    "    with tf.name_scope('one_hot_encoding'):\n",
    "        y_oh = tf.cast(tf.equal(\n",
    "            logits, tf.reduce_max(logits, axis=1)[:, None]), tf.float32)[..., None]\n",
    "\n",
    "        label_oh = tf.one_hot(label, depth=4)[..., None]\n",
    "    with tf.name_scope('confusion_matrix'):\n",
    "        conf_op = tf.reduce_sum(tf.transpose(y_oh, perm=[0, 2, 1]) * label_oh,\n",
    "            axis=0, name='result')\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        y_tot = tf.reduce_sum(conf_op, axis=0, name='label_class_sum')\n",
    "        label_tot = tf.reduce_sum(conf_op, axis=1, name='pred_class_sum')\n",
    "        correct_op = tf.diag_part(conf_op, name='correct_class_sum')\n",
    "        eps = tf.constant([1e-10] * 4, name='eps')\n",
    "        acc_op = tf.reduce_mean(2*correct_op / (y_tot + label_tot + eps), name='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'evaluation/confusion_matrix/result:0' shape=(4, 4) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session started\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[0.16666667]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Session started')\n",
    "    print(conf_op.eval({logits:[[.1, .2, .3, .4], [.1, .2, .3, .4]], label:[3, 0]}))\n",
    "    print(sess.run([acc_op], {logits:[[.1, .2, .3, .4], [.1, .2, .3, .4]], label:[3, 0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#measure_time(acc_op, n_times=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sparse, weighted softmax loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5154,  771, 2557,   46]),\n",
       " <tf.Tensor 'loss/weight_selector:0' shape=(?,) dtype=float64>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_hist = np.load('./data/class_hist.npy')\n",
    "with tf.name_scope('loss'):\n",
    "    weight = tf.constant(1 - np.sqrt(class_hist/class_hist.sum()), name='weights')\n",
    "    weight = tf.gather(weight, label, name='weight_selector')\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(label, logits, weight, scope='weighted_loss')\n",
    "    unweighted_loss = tf.losses.sparse_softmax_cross_entropy(label, logits, scope='unweighted_loss')\n",
    "class_hist, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# measure_time([loss, unweighted_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    learning_rate = tf.Variable(initial_value=.05, trainable=False, name='learning_rate')\n",
    "    global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "    grad_clip = tf.Variable(initial_value=3., trainable=False, name='grad_clip')\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    with tf.name_scope('gradient_clipping'):\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -grad_clip, grad_clip), var) \n",
    "                      for grad, var in gvs]\n",
    "        \n",
    "    opt = optimizer.apply_gradients(capped_gvs, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN/Conv1/Conv_dim10_ker32_pool2/weights:0',\n",
       " 'CNN/Conv1/Conv_dim10_ker32_pool2/BatchNorm/beta:0',\n",
       " 'CNN/Conv2/Conv_dim10_ker32_pool2/weights:0',\n",
       " 'CNN/Conv2/Conv_dim10_ker32_pool2/BatchNorm/beta:0',\n",
       " 'CNN/Conv3/Conv_dim10_ker32_pool2/weights:0',\n",
       " 'CNN/Conv3/Conv_dim10_ker32_pool2/BatchNorm/beta:0',\n",
       " 'RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0',\n",
       " 'RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0',\n",
       " 'classifier/hidden_layer0/fully_connected/weights:0',\n",
       " 'classifier/hidden_layer0/fully_connected/biases:0',\n",
       " 'classifier/hidden_layer1/fully_connected/weights:0',\n",
       " 'classifier/hidden_layer1/fully_connected/biases:0',\n",
       " 'classifier/hidden_layer2/fully_connected/weights:0',\n",
       " 'classifier/hidden_layer2/fully_connected/biases:0',\n",
       " 'classifier/logits/weights:0',\n",
       " 'classifier/logits/biases:0']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name CNN/Conv1/Conv_dim10_ker32_pool2/weights:0 is illegal; using CNN/Conv1/Conv_dim10_ker32_pool2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv1/Conv_dim10_ker32_pool2/weights:0/gradients is illegal; using CNN/Conv1/Conv_dim10_ker32_pool2/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv1/Conv_dim10_ker32_pool2/BatchNorm/beta:0 is illegal; using CNN/Conv1/Conv_dim10_ker32_pool2/BatchNorm/beta_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv1/Conv_dim10_ker32_pool2/BatchNorm/beta:0/gradients is illegal; using CNN/Conv1/Conv_dim10_ker32_pool2/BatchNorm/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv2/Conv_dim10_ker32_pool2/weights:0 is illegal; using CNN/Conv2/Conv_dim10_ker32_pool2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv2/Conv_dim10_ker32_pool2/weights:0/gradients is illegal; using CNN/Conv2/Conv_dim10_ker32_pool2/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv2/Conv_dim10_ker32_pool2/BatchNorm/beta:0 is illegal; using CNN/Conv2/Conv_dim10_ker32_pool2/BatchNorm/beta_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv2/Conv_dim10_ker32_pool2/BatchNorm/beta:0/gradients is illegal; using CNN/Conv2/Conv_dim10_ker32_pool2/BatchNorm/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv3/Conv_dim10_ker32_pool2/weights:0 is illegal; using CNN/Conv3/Conv_dim10_ker32_pool2/weights_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv3/Conv_dim10_ker32_pool2/weights:0/gradients is illegal; using CNN/Conv3/Conv_dim10_ker32_pool2/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv3/Conv_dim10_ker32_pool2/BatchNorm/beta:0 is illegal; using CNN/Conv3/Conv_dim10_ker32_pool2/BatchNorm/beta_0 instead.\n",
      "INFO:tensorflow:Summary name CNN/Conv3/Conv_dim10_ker32_pool2/BatchNorm/beta:0/gradients is illegal; using CNN/Conv3/Conv_dim10_ker32_pool2/BatchNorm/beta_0/gradients instead.\n",
      "INFO:tensorflow:Summary name RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0 is illegal; using RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights_0 instead.\n",
      "INFO:tensorflow:Summary name RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0/gradients is illegal; using RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0 is illegal; using RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases_0 instead.\n",
      "INFO:tensorflow:Summary name RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0/gradients is illegal; using RNN/LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer0/fully_connected/weights:0 is illegal; using classifier/hidden_layer0/fully_connected/weights_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer0/fully_connected/weights:0/gradients is illegal; using classifier/hidden_layer0/fully_connected/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer0/fully_connected/biases:0 is illegal; using classifier/hidden_layer0/fully_connected/biases_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer0/fully_connected/biases:0/gradients is illegal; using classifier/hidden_layer0/fully_connected/biases_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer1/fully_connected/weights:0 is illegal; using classifier/hidden_layer1/fully_connected/weights_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer1/fully_connected/weights:0/gradients is illegal; using classifier/hidden_layer1/fully_connected/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer1/fully_connected/biases:0 is illegal; using classifier/hidden_layer1/fully_connected/biases_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer1/fully_connected/biases:0/gradients is illegal; using classifier/hidden_layer1/fully_connected/biases_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer2/fully_connected/weights:0 is illegal; using classifier/hidden_layer2/fully_connected/weights_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer2/fully_connected/weights:0/gradients is illegal; using classifier/hidden_layer2/fully_connected/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer2/fully_connected/biases:0 is illegal; using classifier/hidden_layer2/fully_connected/biases_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/hidden_layer2/fully_connected/biases:0/gradients is illegal; using classifier/hidden_layer2/fully_connected/biases_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/logits/weights:0 is illegal; using classifier/logits/weights_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/logits/weights:0/gradients is illegal; using classifier/logits/weights_0/gradients instead.\n",
      "INFO:tensorflow:Summary name classifier/logits/biases:0 is illegal; using classifier/logits/biases_0 instead.\n",
      "INFO:tensorflow:Summary name classifier/logits/biases:0/gradients is illegal; using classifier/logits/biases_0/gradients instead.\n"
     ]
    }
   ],
   "source": [
    "train_writer = tf.summary.FileWriter('/tmp/model/hist/', graph=tf.get_default_graph())\n",
    "for v in tf.trainable_variables():\n",
    "    tf.summary.histogram(v.name, v)\n",
    "    tf.summary.histogram(v.name + '/gradients', tf.gradients(loss, v))\n",
    "\n",
    "#measure_time([loss, unweighted_loss, acc_op, opt], n_times=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sess started\n",
      "Evaluating\n",
      "0 / 10 loss: 0.489348\n",
      "1 / 10 loss: 0.418308\n",
      "2 / 10 loss: 0.49641\n",
      "3 / 10 loss: 0.473225\n",
      "4 / 10 loss: 0.482493\n",
      "5 / 10 loss: 0.362709\n",
      "6 / 10 loss: 0.49135\n",
      "7 / 10 loss: 0.406379\n",
      "8 / 10 loss: 0.350535\n",
      "9 / 10 loss: 0.336632\n",
      "Closing threads\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Sess started')\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.global_variables_initializer().run()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    feed_dict={}\n",
    "    init_state = sess.run(r.zero_state)\n",
    "    rnn_feed = {r.init_state : init_state}\n",
    "    feed_dict.update(rnn_feed)\n",
    "    print('Evaluating')\n",
    "    for i in range(10):\n",
    "        t = time.time()\n",
    "        test_output = sess.run([opt, loss, summaries], feed_dict)\n",
    "        train_writer.add_summary(test_output[2], i)\n",
    "        print(i, '/', 10, 'loss:', test_output[1])\n",
    "\n",
    "    print('Closing threads')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
