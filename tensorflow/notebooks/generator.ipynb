{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files: 08527   \n",
      "Reading successful!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data\n",
    "import model\n",
    "import time\n",
    "import shutil\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def_learning_rate = .001\n",
    "def_grad_clip = 5.\n",
    "def_eval_freq = 1\n",
    "def_save_freq = 20\n",
    "def_gpu = 0\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_float('rate', def_learning_rate, 'Learning rate for Adam optimizer [%f]'%def_learning_rate)\n",
    "flags.DEFINE_float('clip', def_grad_clip, 'Clipping gradients during backpropagation [%f]'%def_grad_clip)\n",
    "flags.DEFINE_integer('eval_freq', def_eval_freq, 'Number of samples after model is evaluated on its own input [%d]'%def_eval_freq)\n",
    "flags.DEFINE_integer('save_freq', def_save_freq, 'Number of samples after model checkpoint is saved [%d]'%def_save_freq)\n",
    "flags.DEFINE_integer('gpu', def_gpu, 'GPU ID to use [%d]'%def_gpu)\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(FLAGS.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "g = model.generator(rnn_sizes=[10], fc_sizes=[])\n",
    "feeder = data.random_batch(g.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss, images and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Name scope is good for graph definition for debugging in TensorBoard\n",
    "'''\n",
    "global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "target = tf.placeholder(tf.float32, [g.batch_size, None, model.def_input_dim])\n",
    "\n",
    "with tf.name_scope('linear_regression'):    \n",
    "    loss = tf.reduce_sum((g.outputs-target)**2)    \n",
    "    with tf.name_scope('total'):\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "with tf.name_scope('visualizer'):\n",
    "    plot_buf_placeholder = tf.placeholder(tf.string, [], 'plot_buf_placeholder')\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(plot_buf_placeholder, channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "        \n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.rate)\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    with tf.name_scope('gradient_clipping'):\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -FLAGS.clip, FLAGS.clip), var) \n",
    "                      for grad, var in gvs]\n",
    "        \n",
    "    opt = optimizer.apply_gradients(capped_gvs, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def eval(run_length, sess):\n",
    "    res = np.zeros((g.batch_size, run_length))\n",
    "\n",
    "    state = sess.run(g.zero_state)\n",
    "    x = np.zeros((g.batch_size, 1, model.def_input_dim))\n",
    "    for i in range(run_length):\n",
    "        feed_dict = {\n",
    "            g.keep_prob:1,\n",
    "            g.x:x,\n",
    "            g.init_state:state,\n",
    "            g.seq_len:np.ones((g.batch_size))\n",
    "        }\n",
    "        x, state = sess.run([g.outputs, g.rnn_last_states], feed_dict)\n",
    "        res[:, i] = x.squeeze()\n",
    "        \n",
    "        \n",
    "    return res\n",
    "\n",
    "# http://stackoverflow.com/questions/38543850/\n",
    "def gen_plot(value_to_plot, num_subplots, name=None):\n",
    "    \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "    x = value_to_plot.squeeze()\n",
    "    fig = plt.figure(1)\n",
    "    plt.clf()\n",
    "    for i in range(num_subplots):\n",
    "        plt.subplot(num_subplots, 1, i+1)\n",
    "        plt.plot(x[i])\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, dpi=150, format='png')\n",
    "    if name:\n",
    "        fig.savefig(name, dpi=150, format='png')\n",
    "        print('\\nImage saved to:%s\\n'%name)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    return buf.getvalue()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name optimizer/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0 is illegal; using optimizer/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell/MatMul/Enter_grad/b_acc_3_0 instead.\n",
      "INFO:tensorflow:Summary name LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0 is illegal; using LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0 is illegal; using optimizer/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3_0 instead.\n",
      "INFO:tensorflow:Summary name LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0 is illegal; using LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer/gradients/fully_connected/fully_connected/MatMul_grad/tuple/control_dependency_1:0 is illegal; using optimizer/gradients/fully_connected/fully_connected/MatMul_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected/weights:0 is illegal; using fully_connected/fully_connected/weights_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer/gradients/fully_connected/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0 is illegal; using optimizer/gradients/fully_connected/fully_connected/BiasAdd_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected/biases:0 is illegal; using fully_connected/fully_connected/biases_0 instead.\n"
     ]
    }
   ],
   "source": [
    "summaries = tf.summary.merge([\n",
    "    [(tf.summary.histogram(grad.name, grad), \n",
    "      tf.summary.histogram(var.name, var)) \n",
    "     for grad, var in gvs],\n",
    "    tf.summary.scalar('loss', loss)\n",
    "])\n",
    "im_sum = tf.summary.image('generated', image, max_outputs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Path check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/model/300rnn10--fc---2017-03-05--00-46-14\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "path = g.get_checkpoint_path()\n",
    "if os.path.exists(path):\n",
    "    print('  Found existing path, removing its content...')\n",
    "    shutil.rmtree(path)\n",
    "writer = tf.summary.FileWriter(path, graph=sess.graph)\n",
    "im_path = os.path.join(path, 'demo_img')\n",
    "os.mkdir(im_path)\n",
    "print(writer.get_logdir())\n",
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=1)\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08400 val/sec: 3988\t it: 00000 sample_time: 3.5sec loss: 842.341187\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000030.png\n",
      "\n",
      "\n",
      "Model checkpoint saved to: /tmp/model/300rnn10--fc---2017-03-05--00-46-14/saver-30\n",
      "\n",
      "17400 val/sec: 3873\t it: 00001 sample_time: 7.0sec loss: 5.259467\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000090.png\n",
      "\n",
      "08400 val/sec: 4080\t it: 00002 sample_time: 3.4sec loss: 81.940948\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000120.png\n",
      "\n",
      "18000 val/sec: 4353\t it: 00003 sample_time: 9.0sec loss: 34.938259\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000181.png\n",
      "\n",
      "17400 val/sec: 2343\t it: 00004 sample_time: 8.8sec loss: 102.063690\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000241.png\n",
      "\n",
      "17400 val/sec: 3656\t it: 00005 sample_time: 7.5sec loss: 28.526056\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000301.png\n",
      "\n",
      "08400 val/sec: 3707\t it: 00006 sample_time: 3.7sec loss: 90.948547\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000331.png\n",
      "\n",
      "08400 val/sec: 2228\t it: 00007 sample_time: 5.2sec loss: 41.720726\n",
      "\n",
      "Image saved to:/tmp/model/300rnn10--fc---2017-03-05--00-46-14/demo_img/000361.png\n",
      "\n",
      "08400 val/sec: 3837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1ef601a0a84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Training happens here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfetch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/botcs/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/botcs/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/botcs/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/botcs/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/botcs/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(feeder):\n",
    "    state = sess.run(g.zero_state)\n",
    "    x_feed, label_feed, lens_feed = batch\n",
    "    target_feed = np.roll(x_feed, 1) \n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx in range(0, lens_feed.max(), g.time_steps):\n",
    "        data_window = x_feed[:, idx:idx+g.time_steps]\n",
    "        target_window = target_feed[:, idx:idx+g.time_steps]\n",
    "        lens_window = lens_feed-idx\n",
    "        \n",
    "        feed_dict = {\n",
    "            g.x:data_window,\n",
    "            g.init_state:state,\n",
    "            g.seq_len:lens_window,\n",
    "            target:target_window\n",
    "        }\n",
    "        fetch_dict = {\n",
    "            'opt' : opt,\n",
    "            'step' : global_step,\n",
    "            'loss' : loss,\n",
    "            'state' : g.rnn_last_states\n",
    "        }\n",
    "        \n",
    "        start_window_time = time.time()\n",
    "        \n",
    "        # Training happens here\n",
    "        fetch = sess.run(fetch_dict, feed_dict)\n",
    "        state = fetch['state']\n",
    "        #######################\n",
    "        \n",
    "        window_time = time.time() - start_window_time\n",
    "        valpsec = g.time_steps / window_time\n",
    "        \n",
    "        if idx % (2 * g.time_steps) == 0:\n",
    "            sum_eval = sess.run(summaries, feed_dict)\n",
    "            writer.add_summary(summary=sum_eval, global_step=fetch['step'])\n",
    "            print('\\r%05d val/sec: %d'%(idx, valpsec), end='', flush=True)\n",
    "            \n",
    "    sample_time = time.time() - start_time\n",
    "    print('\\t it: %05d sample_time: %03.1fs loss: %f'%(i, sample_time, fetch['loss']))\n",
    "    \n",
    "    if i % FLAGS.eval_freq == 0:\n",
    "        fname = os.path.join(im_path, '%05d.png'%fetch['step'])\n",
    "        plot = gen_plot(eval(3*g.time_steps, sess), 3, fname)\n",
    "        feed_dict[plot_buf_placeholder] = plot\n",
    "        writer.add_summary(im_sum.eval(feed_dict), global_step=fetch['step'])\n",
    "        \n",
    "    \n",
    "    if i % FLAGS.save_freq == 0: \n",
    "        path = saver.save(sess, g.get_checkpoint_path()+'/saver', fetch['step'])\n",
    "        print('\\nModel checkpoint saved to: %s\\n'%path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/model/1200rnn128--fc64---2017-03-02--02-55-04'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_checkpoint_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0032777786254883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "time.sleep(3)\n",
    "t = time.time() - t\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
