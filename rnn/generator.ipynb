{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files: 08527   \n",
      "Reading successful!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data\n",
    "import model\n",
    "import time\n",
    "\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rate = .001\n",
    "grad_clip = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "g = model.generator(rnn_sizes=[10], fc_sizes=[])\n",
    "feeder = data.batch_pool(g.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/fully_connected/Reshape_1:0' shape=(4, ?, 1) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loss, images and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Name scope is good for graph definition for debugging in TensorBoard\n",
    "'''\n",
    "global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "target = tf.placeholder(tf.float32, [g.batch_size, None, model.def_input_dim])\n",
    "\n",
    "with tf.name_scope('linear_regression'):    \n",
    "    loss = tf.reduce_sum((g.outputs-target)**2)    \n",
    "    with tf.name_scope('total'):\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "with tf.name_scope('visualizer'):\n",
    "    # http://stackoverflow.com/questions/38543850/\n",
    "    def gen_plot(value_to_plot, subplots):\n",
    "        \"\"\"Create a pyplot plot and save to buffer.\"\"\"\n",
    "        x = value_to_plot.squeeze()\n",
    "        fig = plt.figure(1)\n",
    "        plt.clf()\n",
    "        for i in range(subplots):\n",
    "            plt.subplot(subplots, 1, i+1)\n",
    "            plt.plot(x[i])\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, dpi=600, format='png')\n",
    "        plt.close(fig)\n",
    "        buf.seek(0)\n",
    "        return buf.getvalue()\n",
    "    \n",
    "    plot_buf_placeholder = tf.placeholder(tf.string, [], 'plot_buf_placeholder')\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(plot_buf_placeholder, channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "        \n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    with tf.name_scope('gradient_clipping'):\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -grad_clip, grad_clip), var) \n",
    "                      for grad, var in gvs]\n",
    "        \n",
    "    opt = optimizer.apply_gradients(capped_gvs, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(run_length, sess):\n",
    "    res = np.zeros((g.batch_size, run_length))\n",
    "\n",
    "    state = sess.run(g.zero_state)\n",
    "    x = np.zeros((g.batch_size, 1, model.def_input_dim))\n",
    "    for i in range(run_length):\n",
    "        feed_dict = {\n",
    "            g.x:x,\n",
    "            g.init_state:state,\n",
    "            g.seq_len:np.ones((g.batch_size))\n",
    "        }\n",
    "        x, state = sess.run([g.outputs, g.rnn_last_states], feed_dict)\n",
    "        res[:, i] = x.squeeze()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name optimizer_1/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0 is illegal; using optimizer_1/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell/MatMul/Enter_grad/b_acc_3_0 instead.\n",
      "INFO:tensorflow:Summary name LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0 is illegal; using LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer_1/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0 is illegal; using optimizer_1/gradients/LSTM/dynamic_wrapper/rnn/while/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3_0 instead.\n",
      "INFO:tensorflow:Summary name LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0 is illegal; using LSTM/dynamic_wrapper/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer_1/gradients/fully_connected/fully_connected/MatMul_grad/tuple/control_dependency_1:0 is illegal; using optimizer_1/gradients/fully_connected/fully_connected/MatMul_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected/weights:0 is illegal; using fully_connected/fully_connected/weights_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer_1/gradients/fully_connected/fully_connected/BiasAdd_grad/tuple/control_dependency_1:0 is illegal; using optimizer_1/gradients/fully_connected/fully_connected/BiasAdd_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected/biases:0 is illegal; using fully_connected/fully_connected/biases_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer_1/gradients/fully_connected/fully_connected_1/MatMul_grad/tuple/control_dependency_1:0 is illegal; using optimizer_1/gradients/fully_connected/fully_connected_1/MatMul_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected_1/weights:0 is illegal; using fully_connected/fully_connected_1/weights_0 instead.\n",
      "INFO:tensorflow:Summary name optimizer_1/gradients/fully_connected/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1:0 is illegal; using optimizer_1/gradients/fully_connected/fully_connected_1/BiasAdd_grad/tuple/control_dependency_1_0 instead.\n",
      "INFO:tensorflow:Summary name fully_connected/fully_connected_1/biases:0 is illegal; using fully_connected/fully_connected_1/biases_0 instead.\n"
     ]
    }
   ],
   "source": [
    "summaries = tf.summary.merge([\n",
    "    [(tf.summary.histogram(grad.name, grad), \n",
    "      tf.summary.histogram(var.name, var)) \n",
    "     for grad, var in gvs],\n",
    "    tf.summary.scalar('loss', loss)\n",
    "])\n",
    "im_sum = tf.summary.image('generated', image, max_outputs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/model/1200rnn128--fc64---2017-03-02--04-00-18\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "writer = tf.summary.FileWriter(\n",
    "    g.get_checkpoint_path(), graph=sess.graph)\n",
    "print(writer.get_logdir())\n",
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=1)\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16800 val/sec: 916\t it: 00000 sample_time: 30.146sec loss: 50.942154\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-16\n",
      "16800 val/sec: 8887\t it: 00001 sample_time: 28.901sec loss: 41.299965\n",
      "14400 val/sec: 1304\t it: 00002 sample_time: 24.930sec loss: 49.153427\n",
      "07200 val/sec: 9691\t it: 00003 sample_time: 14.184sec loss: 65.822708\n",
      "16800 val/sec: 8154\t it: 00004 sample_time: 29.187sec loss: 18.445307\n",
      "14400 val/sec: 9700\t it: 00005 sample_time: 25.425sec loss: 3.786272\n",
      "16800 val/sec: 9759\t it: 00006 sample_time: 29.162sec loss: 38.295128\n",
      "07200 val/sec: 9728\t it: 00007 sample_time: 14.575sec loss: 32.553986\n",
      "16800 val/sec: 895\t it: 00008 sample_time: 29.100sec loss: 14.089001\n",
      "16800 val/sec: 9241\t it: 00009 sample_time: 28.785sec loss: 36.964184\n",
      "07200 val/sec: 9744\t it: 00010 sample_time: 14.861sec loss: 25.209452\n",
      "16800 val/sec: 9756\t it: 00011 sample_time: 28.987sec loss: 3.080713\n",
      "16800 val/sec: 9808\t it: 00012 sample_time: 30.851sec loss: 22.208879\n",
      "16800 val/sec: 9847\t it: 00013 sample_time: 29.359sec loss: 23.536709\n",
      "16800 val/sec: 9207\t it: 00014 sample_time: 28.538sec loss: 5.930479\n",
      "09600 val/sec: 839\t it: 00015 sample_time: 18.411sec loss: 1.322091\n",
      "14400 val/sec: 1035\t it: 00016 sample_time: 26.197sec loss: 11.886642\n",
      "09600 val/sec: 2787\t it: 00017 sample_time: 15.549sec loss: 1.491258\n",
      "16800 val/sec: 1018\t it: 00018 sample_time: 29.722sec loss: 2.257906\n",
      "09600 val/sec: 1185\t it: 00019 sample_time: 18.143sec loss: 5.751822\n",
      "09600 val/sec: 1082\t it: 00020 sample_time: 17.196sec loss: 19.093245\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-267\n",
      "07200 val/sec: 9773\t it: 00021 sample_time: 15.277sec loss: 40.616779\n",
      "16800 val/sec: 9492\t it: 00022 sample_time: 30.265sec loss: 21.190647\n",
      "09600 val/sec: 797\t it: 00023 sample_time: 19.457sec loss: 12.249115\n",
      "09600 val/sec: 993\t it: 00024 sample_time: 18.946sec loss: 9.741517\n",
      "07200 val/sec: 974\t it: 00025 sample_time: 14.491sec loss: 34.559486\n",
      "16800 val/sec: 9544\t it: 00026 sample_time: 29.003sec loss: 20.468603\n",
      "16800 val/sec: 8721\t it: 00027 sample_time: 30.046sec loss: 11.090564\n",
      "12000 val/sec: 9734\t it: 00028 sample_time: 22.539sec loss: 7.640296\n",
      "07200 val/sec: 1037\t it: 00029 sample_time: 14.324sec loss: 21.690662\n",
      "07200 val/sec: 1008\t it: 00030 sample_time: 14.520sec loss: 31.572613\n",
      "16800 val/sec: 9147\t it: 00031 sample_time: 28.460sec loss: 15.042774\n",
      "16800 val/sec: 9479\t it: 00032 sample_time: 28.514sec loss: 11.916791\n",
      "16800 val/sec: 9895\t it: 00033 sample_time: 28.330sec loss: 8.206255\n",
      "12000 val/sec: 2303\t it: 00034 sample_time: 19.777sec loss: 14.311595\n",
      "07200 val/sec: 1008\t it: 00035 sample_time: 13.731sec loss: 50.707214\n",
      "16800 val/sec: 9775\t it: 00036 sample_time: 28.637sec loss: 0.308054\n",
      "07200 val/sec: 9809\t it: 00037 sample_time: 14.189sec loss: 34.941154\n",
      "12000 val/sec: 5841\t it: 00038 sample_time: 18.623sec loss: 2.270968\n",
      "12000 val/sec: 1012\t it: 00039 sample_time: 21.599sec loss: 7.059310\n",
      "16800 val/sec: 9822\t it: 00040 sample_time: 28.073sec loss: 17.919714\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-502\n",
      "12000 val/sec: 4102\t it: 00041 sample_time: 19.121sec loss: 1.759343\n",
      "07200 val/sec: 1015\t it: 00042 sample_time: 14.743sec loss: 29.390305\n",
      "07200 val/sec: 1042\t it: 00043 sample_time: 14.117sec loss: 26.523071\n",
      "14400 val/sec: 30394\t it: 00044 sample_time: 22.051sec loss: 0.074458\n",
      "07200 val/sec: 985\t it: 00045 sample_time: 14.737sec loss: 37.937572\n",
      "16800 val/sec: 1079\t it: 00046 sample_time: 28.504sec loss: 8.466700\n",
      "16800 val/sec: 8584\t it: 00047 sample_time: 28.848sec loss: 6.870603\n",
      "16800 val/sec: 9074\t it: 00048 sample_time: 29.032sec loss: 19.183769\n",
      "16800 val/sec: 999\t it: 00049 sample_time: 29.786sec loss: 9.195268\n",
      "07200 val/sec: 967\t it: 00050 sample_time: 15.248sec loss: 31.450016\n",
      "16800 val/sec: 9462\t it: 00051 sample_time: 29.164sec loss: 10.477822\n",
      "16800 val/sec: 9481\t it: 00052 sample_time: 29.045sec loss: 22.057718\n",
      "07200 val/sec: 945\t it: 00053 sample_time: 15.398sec loss: 41.434208\n",
      "16800 val/sec: 9771\t it: 00054 sample_time: 29.221sec loss: 7.787113\n",
      "16800 val/sec: 9242\t it: 00055 sample_time: 28.329sec loss: 8.554850\n",
      "07200 val/sec: 1000\t it: 00056 sample_time: 15.141sec loss: 20.307608\n",
      "16800 val/sec: 9699\t it: 00057 sample_time: 28.537sec loss: 8.768681\n",
      "07200 val/sec: 8571\t it: 00058 sample_time: 14.517sec loss: 72.982010\n",
      "16800 val/sec: 1067\t it: 00059 sample_time: 28.547sec loss: 7.963565\n",
      "16800 val/sec: 1037\t it: 00060 sample_time: 28.708sec loss: 13.733986\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-747\n",
      "16800 val/sec: 1029\t it: 00061 sample_time: 29.366sec loss: 6.132715\n",
      "14400 val/sec: 8959\t it: 00062 sample_time: 25.771sec loss: 5.975312\n",
      "16800 val/sec: 9794\t it: 00063 sample_time: 28.941sec loss: 12.125429\n",
      "12000 val/sec: 4269\t it: 00064 sample_time: 18.941sec loss: 2.040477\n",
      "16800 val/sec: 9900\t it: 00065 sample_time: 28.865sec loss: 14.779265\n",
      "16800 val/sec: 9800\t it: 00066 sample_time: 28.820sec loss: 5.921338\n",
      "16800 val/sec: 9058\t it: 00067 sample_time: 29.059sec loss: 4.660151\n",
      "07200 val/sec: 1067\t it: 00068 sample_time: 14.550sec loss: 21.023043\n",
      "16800 val/sec: 994\t it: 00069 sample_time: 29.950sec loss: 5.400646\n",
      "16800 val/sec: 9861\t it: 00070 sample_time: 28.112sec loss: 11.805260\n",
      "16800 val/sec: 9908\t it: 00071 sample_time: 28.570sec loss: 22.191170\n",
      "16800 val/sec: 2484\t it: 00072 sample_time: 28.940sec loss: 3.528078\n",
      "16800 val/sec: 9906\t it: 00073 sample_time: 29.424sec loss: 12.084002\n",
      "07200 val/sec: 919\t it: 00074 sample_time: 14.788sec loss: 37.032421\n",
      "12000 val/sec: 9616\t it: 00075 sample_time: 23.111sec loss: 5.420367\n",
      "09600 val/sec: 1003\t it: 00076 sample_time: 17.989sec loss: 8.495430\n",
      "07200 val/sec: 9577\t it: 00077 sample_time: 13.779sec loss: 84.573387\n",
      "16800 val/sec: 1009\t it: 00078 sample_time: 28.593sec loss: 11.146205\n",
      "16800 val/sec: 8780\t it: 00079 sample_time: 29.217sec loss: 8.272948\n",
      "09600 val/sec: 1826\t it: 00080 sample_time: 16.932sec loss: 4.237993\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-1007\n",
      "16800 val/sec: 9152\t it: 00081 sample_time: 29.388sec loss: 18.206329\n",
      "07200 val/sec: 9443\t it: 00082 sample_time: 14.703sec loss: 63.196457\n",
      "09600 val/sec: 1333\t it: 00083 sample_time: 16.854sec loss: 12.122610\n",
      "16800 val/sec: 9486\t it: 00084 sample_time: 29.367sec loss: 17.135330\n",
      "07200 val/sec: 1003\t it: 00085 sample_time: 14.270sec loss: 18.531590\n",
      "16800 val/sec: 9875\t it: 00086 sample_time: 28.104sec loss: 2.247400\n",
      "14400 val/sec: 1347\t it: 00087 sample_time: 23.674sec loss: 7.841383\n",
      "12000 val/sec: 1360\t it: 00088 sample_time: 20.228sec loss: 16.826277\n",
      "07200 val/sec: 9422\t it: 00089 sample_time: 14.739sec loss: 34.788357\n",
      "09600 val/sec: 16074\t it: 00090 sample_time: 14.937sec loss: 0.065723\n",
      "16800 val/sec: 8708\t it: 00091 sample_time: 30.013sec loss: 4.094666\n",
      "07200 val/sec: 876\t it: 00092 sample_time: 15.222sec loss: 31.386246\n",
      "16800 val/sec: 9201\t it: 00093 sample_time: 29.440sec loss: 3.534757\n",
      "16800 val/sec: 901\t it: 00094 sample_time: 31.274sec loss: 5.691728\n",
      "07200 val/sec: 939\t it: 00095 sample_time: 14.984sec loss: 29.382038\n",
      "07200 val/sec: 9388\t it: 00096 sample_time: 14.700sec loss: 21.045994\n",
      "16800 val/sec: 9867\t it: 00097 sample_time: 29.116sec loss: 21.641998\n",
      "16800 val/sec: 937\t it: 00098 sample_time: 29.841sec loss: 24.367075\n",
      "16800 val/sec: 1017\t it: 00099 sample_time: 28.097sec loss: 3.061115\n",
      "16800 val/sec: 9533\t it: 00100 sample_time: 28.195sec loss: 15.110114\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-1247\n",
      "16800 val/sec: 8995\t it: 00101 sample_time: 28.682sec loss: 8.889071\n",
      "16800 val/sec: 9240\t it: 00102 sample_time: 29.626sec loss: 15.147389\n",
      "16800 val/sec: 1003\t it: 00103 sample_time: 29.084sec loss: 6.641716\n",
      "16800 val/sec: 1471\t it: 00104 sample_time: 27.888sec loss: 3.680895\n",
      "16800 val/sec: 1010\t it: 00105 sample_time: 31.049sec loss: 11.260429\n",
      "16800 val/sec: 965\t it: 00106 sample_time: 30.509sec loss: 6.656921\n",
      "16800 val/sec: 8566\t it: 00107 sample_time: 30.547sec loss: 0.991456\n",
      "07200 val/sec: 853\t it: 00108 sample_time: 15.446sec loss: 27.388145\n",
      "16800 val/sec: 9730\t it: 00109 sample_time: 29.557sec loss: 21.607170\n",
      "16800 val/sec: 917\t it: 00110 sample_time: 29.639sec loss: 15.646649\n",
      "16800 val/sec: 1013\t it: 00111 sample_time: 30.303sec loss: 9.257187\n",
      "14400 val/sec: 1060\t it: 00112 sample_time: 26.053sec loss: 11.325668\n",
      "07200 val/sec: 1014\t it: 00113 sample_time: 14.432sec loss: 49.560501\n",
      "09600 val/sec: 48528\t it: 00114 sample_time: 14.928sec loss: 0.017815\n",
      "12000 val/sec: 1818\t it: 00115 sample_time: 19.378sec loss: 309.984680\n",
      "09600 val/sec: 3432\t it: 00116 sample_time: 15.376sec loss: 1.587064\n",
      "16800 val/sec: 1048\t it: 00117 sample_time: 27.756sec loss: 13.418798\n",
      "16800 val/sec: 9679\t it: 00118 sample_time: 27.900sec loss: 10.323479\n",
      "16800 val/sec: 1013\t it: 00119 sample_time: 27.793sec loss: 8.942852\n",
      "16800 val/sec: 9264\t it: 00120 sample_time: 28.727sec loss: 10.444977\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-1517\n",
      "07200 val/sec: 972\t it: 00121 sample_time: 14.641sec loss: 26.393436\n",
      "12000 val/sec: 13028\t it: 00122 sample_time: 18.921sec loss: 126.661217\n",
      "12000 val/sec: 1000\t it: 00123 sample_time: 21.426sec loss: 10.028037\n",
      "09600 val/sec: 9725\t it: 00124 sample_time: 18.668sec loss: 6.745407\n",
      "16800 val/sec: 9943\t it: 00125 sample_time: 29.474sec loss: 14.940587\n",
      "16800 val/sec: 797\t it: 00126 sample_time: 30.180sec loss: 14.669258\n",
      "16800 val/sec: 9878\t it: 00127 sample_time: 30.688sec loss: 7.038166\n",
      "07200 val/sec: 9234\t it: 00128 sample_time: 14.729sec loss: 24.966623\n",
      "12000 val/sec: 957\t it: 00129 sample_time: 22.418sec loss: 12.689993\n",
      "14400 val/sec: 9197\t it: 00130 sample_time: 26.786sec loss: 4.970679\n",
      "16800 val/sec: 9571\t it: 00131 sample_time: 29.200sec loss: 6.910940\n",
      "09600 val/sec: 7142\t it: 00132 sample_time: 15.959sec loss: 0.628861\n",
      "09600 val/sec: 1498\t it: 00133 sample_time: 17.109sec loss: 5.112456\n",
      "16800 val/sec: 9258\t it: 00134 sample_time: 29.328sec loss: 12.758154\n",
      "16800 val/sec: 9052\t it: 00135 sample_time: 28.596sec loss: 5.007303\n",
      "16800 val/sec: 1051\t it: 00136 sample_time: 28.610sec loss: 15.308358\n",
      "16800 val/sec: 1026\t it: 00137 sample_time: 28.168sec loss: 8.646663\n",
      "07200 val/sec: 1048\t it: 00138 sample_time: 13.919sec loss: 34.865528\n",
      "16800 val/sec: 9400\t it: 00139 sample_time: 28.393sec loss: 6.134243\n",
      "16800 val/sec: 1036\t it: 00140 sample_time: 27.932sec loss: 8.156820\n",
      "\n",
      "Model checkpoint saved to:\n",
      " /tmp/model/1200rnn128--fc64---2017-03-02--04-00-18/saver-1766\n",
      "07200 val/sec: 8389\t it: 00141 sample_time: 14.127sec loss: 25.142073\n",
      "16800 val/sec: 9150\t it: 00142 sample_time: 28.329sec loss: 6.812005\n",
      "16800 val/sec: 1018\t it: 00143 sample_time: 29.005sec loss: 7.629828\n",
      "16800 val/sec: 891\t it: 00144 sample_time: 29.513sec loss: 1.931577\n",
      "07200 val/sec: 9310\t it: 00145 sample_time: 14.794sec loss: 31.492886\n",
      "16800 val/sec: 8632\t it: 00146 sample_time: 29.451sec loss: 17.770617\n",
      "07200 val/sec: 834\t it: 00147 sample_time: 16.385sec loss: 29.373230\n",
      "07200 val/sec: 970\t it: 00148 sample_time: 15.341sec loss: 35.193871\n",
      "14400 val/sec: 9506\t it: 00149 sample_time: 25.397sec loss: 6.530264\n",
      "16800 val/sec: 9692\t it: 00150 sample_time: 29.583sec loss: 1.259368\n",
      "16800 val/sec: 9633\t it: 00151 sample_time: 29.537sec loss: 5.148777\n",
      "07200 val/sec: 8175"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(feeder):\n",
    "    state = sess.run(g.zero_state)\n",
    "    x_feed, label_feed, lens_feed = batch\n",
    "    target_feed = np.roll(x_feed, 1) \n",
    "    \n",
    "    start_time = time.time()\n",
    "    for idx in range(0, lens_feed.max(), g.time_steps):\n",
    "        data_window = x_feed[:, idx:idx+g.time_steps]\n",
    "        target_window = target_feed[:, idx:idx+g.time_steps]\n",
    "        lens_window = lens_feed-idx\n",
    "        \n",
    "        feed_dict = {\n",
    "            g.x:data_window,\n",
    "            g.init_state:state,\n",
    "            g.seq_len:lens_window,\n",
    "            target:target_window\n",
    "        }\n",
    "        \n",
    "        if idx == 0: init_feed_dict = feed_dict\n",
    "        \n",
    "        fetch_dict = {\n",
    "            'opt' : opt,\n",
    "            'step' : global_step,\n",
    "            'loss' : loss,\n",
    "            'state' : g.rnn_last_states\n",
    "        }\n",
    "        start_window_time = time.time()\n",
    "        fetch = sess.run(fetch_dict, feed_dict)\n",
    "        window_time = time.time() - start_window_time\n",
    "        valpsec = g.time_steps / window_time\n",
    "        state = fetch['state']\n",
    "        \n",
    "        if idx % (2 * g.time_steps) == 0:\n",
    "            sum_eval = sess.run(summaries, feed_dict)\n",
    "            writer.add_summary(summary=sum_eval, global_step=fetch['step'])\n",
    "            print('\\r%05d val/sec: %d'%(idx, valpsec), end='', flush=True)\n",
    "            \n",
    "    sample_time = time.time() - start_time\n",
    "    print('\\t it: %05d sample_time: %03.3fsec loss: %f'%(i, sample_time, fetch['loss']))\n",
    "    outputs = g.outputs.eval(init_feed_dict)\n",
    "    plot = gen_plot(outputs, 3)\n",
    "    feed_dict[plot_buf_placeholder] = plot\n",
    "    writer.add_summary(im_sum.eval(feed_dict), global_step=fetch['step'])\n",
    "    \n",
    "    \n",
    "    if i%20 == 0: \n",
    "        path = saver.save(sess, g.get_checkpoint_path()+'/saver', fetch['step'])\n",
    "        print('\\nModel checkpoint saved to:\\n', path)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/model/1200rnn128--fc64---2017-03-02--02-55-04'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_checkpoint_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0032777786254883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "time.sleep(3)\n",
    "t = time.time() - t\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njhsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb95f5ba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.show(plt.plot(np.ones((4, 10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
