{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-f',\n",
       " '/run/user/1023/jupyter/kernel-60c851a9-9483-4ea8-98eb-41ca76c6e1e3.json']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "def_batch_size = 4\n",
    "def_time_steps = 250\n",
    "def_input_dim = 1 # Scalar\n",
    "# normal sinus rhythm, atrial fibrillation (AF), an alternative rhythm, or is too noisy\n",
    "def_label_dim = 4 \n",
    "def_keep_prob = 0.5\n",
    "# Model Hyperparameters\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_integer('batch_size', def_batch_size, 'Number of samples per update cycle [%d]'%def_batch_size)\n",
    "flags.DEFINE_integer('time_steps', def_time_steps, 'Length of unrolled LSTM network [%d]'%def_time_steps)\n",
    "flags.DEFINE_string('rnn_sizes', '30, 30, 30', 'Stacked RNN state size. Use comma separated integers [\"10, 10, 10\"]')\n",
    "flags.DEFINE_string('fc_sizes', '30, 10', 'Size of fully connected layers. Use comma separated integers [\"30, 10\"]')\n",
    "flags.DEFINE_float('keep_prob', def_keep_prob, 'Probability of keeping an activation value after the DROPOUT layer, during training [%f]'%def_keep_prob)\n",
    "flags.DEFINE_string('model_path', '/tmp/model', 'Logs will be saved to this directory')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS._parse_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class generator(object):\n",
    "    '''\n",
    "    Generate continous time series, using stacked LSTM network.\n",
    "    generator will return an object, whose main fields are tensorflow graph nodes.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def get_input(self, batch_size):\n",
    "        with tf.variable_scope('input'):\n",
    "            x = tf.placeholder(tf.float32, [batch_size, None, def_input_dim], name='X')\n",
    "            seq_len = tf.placeholder(tf.int16, [None], name='length')\n",
    "        return x, seq_len\n",
    "    \n",
    "    def get_rnn(self, x, seq_len, batch_size, rnn_sizes, keep_prob):\n",
    "        with tf.variable_scope('LSTM'):\n",
    "            rnn_tuple_state = []\n",
    "\n",
    "            for size in rnn_sizes:\n",
    "                shape = [2, batch_size, size]\n",
    "                ph = tf.placeholder(tf.float32, shape)\n",
    "                rnn_tuple_state.append(\n",
    "                    tf.contrib.rnn.LSTMStateTuple(ph[0], ph[1]))\n",
    "                \n",
    "            rnn_tuple_state = tuple(rnn_tuple_state)\n",
    "\n",
    "            cells = [tf.contrib.rnn.BasicLSTMCell(size) for size in rnn_sizes]\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            cells = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob) \n",
    "                     for cell in cells]\n",
    "            multi_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "            \n",
    "            with tf.variable_scope('dynamic_wrapper'):\n",
    "                outputs, last_states = tf.nn.dynamic_rnn(\n",
    "                    initial_state=rnn_tuple_state,\n",
    "                    inputs=x, cell=multi_cell, \n",
    "                    sequence_length=seq_len)\n",
    "        \n",
    "        return outputs, last_states, keep_prob\n",
    "\n",
    "    def get_fc(self, in_node, fc_sizes, out_dim, keep_prob):\n",
    "        with tf.variable_scope('fully_connected'):\n",
    "            act_fn = tf.nn.relu\n",
    "            h = in_node\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            for size in fc_sizes:\n",
    "                h = tf.contrib.layers.fully_connected(h, size, act_fn)\n",
    "                tf.nn.dropout(h, keep_prob)\n",
    "            preds = tf.contrib.layers.fully_connected(h, out_dim, None)\n",
    "        return preds, keep_prob\n",
    "    \n",
    "    def get_name(self):\n",
    "        rnn_sizes = [str(s) for s in self.rnn_sizes]\n",
    "        fc_sizes = [str(s) for s in self.fc_sizes]\n",
    "        name = 'rnn' + '-'.join(rnn_sizes) + '--fc' + '-'.join(fc_sizes)\n",
    "        name += '---' + time.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "        return name\n",
    "    \n",
    "    def build_graph(self, model_name=None):\n",
    "        # tf.reset_default_graph()\n",
    "        if not model_name:\n",
    "            model_name = self.get_name()\n",
    "        self.name = model_name\n",
    "        \n",
    "        \n",
    "        self.keep_prob = tf.placeholder_with_default(self.def_keep_prob, [], 'keep_prob')\n",
    "        \n",
    "        self.x, self.seq_len = self.get_input(self.batch_size)\n",
    "        \n",
    "        self.rnn_outputs, self.rnn_last_states, self.rnn_keep_prob = self.get_rnn(\n",
    "            self.x, self.seq_len, self.batch_size, self.rnn_sizes, self.keep_prob)\n",
    "\n",
    "        self.outputs, self.fc_keep_prob = self.get_fc(\n",
    "            self.rnn_outputs, self.fc_sizes, def_input_dim, self.keep_prob)\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "    def get_checkpoint_path(self):\n",
    "        return os.path.join(self.model_path, self.name)\n",
    "        \n",
    "    def save_graph(self, sess):\n",
    "        save_path = self.saver.save(sess, self.get_checkpoint_path())\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "    def __init__(self,\n",
    "            batch_size=FLAGS.batch_size,\n",
    "            time_steps=FLAGS.time_steps,\n",
    "            rnn_sizes=[int(s) for s in FLAGS.rnn_sizes.split(',')],\n",
    "            fc_sizes=[int(s) for s in FLAGS.fc_sizes.split(',')],\n",
    "            keep_prob=FLAGS.keep_prob,\n",
    "            model_path=FLAGS.model_path,\n",
    "            model_name=None):\n",
    "        '''\n",
    "        Initializer default vales use tf.app.flags\n",
    "        returns an object, whose main fields are tensorflow graph nodes.\n",
    "        \n",
    "        batch_size: int, Number of samples to process in parallel. \n",
    "        time_steps: int, Maximum number of time steps which the model use for backprop\n",
    "        rnn_sizes: [int, [int...]] Size of corresponding LSTM cell's hidden state\n",
    "        fc_sizes: [int, [int...]] Size of fc layers connected to the last LSTM cell's output\n",
    "        keep_prob: float, Probability of keeping a value in DROPOUT layers\n",
    "        model_path: str, path/to/model/dir\n",
    "        '''\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        self.rnn_sizes = rnn_sizes\n",
    "        self.fc_sizes = fc_sizes\n",
    "        self.def_keep_prob = keep_prob\n",
    "        self.model_path = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifier(object):\n",
    "    '''\n",
    "    Classify continous time series, using stacked LSTM network.\n",
    "    classifier will return an object, whose main fields are tensorflow graph nodes.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def get_input(self, batch_size):\n",
    "        with tf.variable_scope('input'):\n",
    "            x = tf.placeholder(tf.float32, [batch_size, None, def_input_dim], name='X')\n",
    "            seq_len = tf.placeholder(tf.int16, [None], name='length')\n",
    "        return x, seq_len\n",
    "    \n",
    "    def get_rnn(self, x, seq_len, batch_size, rnn_sizes, keep_prob):\n",
    "        with tf.variable_scope('LSTM'):\n",
    "            rnn_tuple_state = []\n",
    "\n",
    "            for size in rnn_sizes:\n",
    "                shape = [2, batch_size, size]\n",
    "                ph = tf.placeholder(tf.float32, shape)\n",
    "                rnn_tuple_state.append(\n",
    "                    tf.contrib.rnn.LSTMStateTuple(ph[0], ph[1]))\n",
    "                \n",
    "            rnn_tuple_state = tuple(rnn_tuple_state)\n",
    "\n",
    "            cells = [tf.contrib.rnn.BasicLSTMCell(size) for size in rnn_sizes]\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            cells = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob) \n",
    "                     for cell in cells]\n",
    "            multi_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "            \n",
    "            with tf.variable_scope('dynamic_wrapper'):\n",
    "                outputs, last_states = tf.nn.dynamic_rnn(\n",
    "                    initial_state=rnn_tuple_state,\n",
    "                    inputs=x, cell=multi_cell, \n",
    "                    sequence_length=seq_len)\n",
    "                zero_state = multi_cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "        return outputs, last_states, keep_prob, rnn_tuple_state, zero_state\n",
    "\n",
    "    def get_fc(self, in_node, fc_sizes, out_dim, keep_prob):\n",
    "        with tf.variable_scope('fully_connected'):\n",
    "            act_fn = tf.nn.relu\n",
    "            h = in_node\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            for size in fc_sizes:\n",
    "                h = tf.contrib.layers.fully_connected(h, size, act_fn)\n",
    "                tf.nn.dropout(h, keep_prob)\n",
    "            preds = tf.contrib.layers.fully_connected(h, out_dim, None)\n",
    "        return preds, keep_prob\n",
    "    \n",
    "    def get_name(self):\n",
    "        rnn_sizes = [str(s) for s in self.rnn_sizes]\n",
    "        fc_sizes = [str(s) for s in self.fc_sizes]\n",
    "        name = 'rnn' + '-'.join(rnn_sizes) + '--fc' + '-'.join(fc_sizes)\n",
    "        name += '---' + time.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "        return name\n",
    "    \n",
    "    def build_graph(self, model_name=None):\n",
    "        # tf.reset_default_graph()\n",
    "        if not model_name:\n",
    "            model_name = self.get_name()\n",
    "        self.name = model_name\n",
    "        \n",
    "        \n",
    "        self.keep_prob = tf.placeholder_with_default(self.def_keep_prob, [], 'keep_prob')\n",
    "        \n",
    "        self.x, self.seq_len = self.get_input(self.batch_size)\n",
    "        \n",
    "        #with tf.variable_scope('classifier'):\n",
    "        \n",
    "        rnn = self.get_rnn(\n",
    "            self.x, self.seq_len, self.batch_size, self.rnn_sizes, self.keep_prob)\n",
    "        self.rnn_outputs, self.rnn_last_states, self.rnn_keep_prob = rnn[:3]\n",
    "        self.init_state, self.zero_state = rnn[3:]\n",
    "        \n",
    "        \n",
    "        # Last layer's tuple, second element: (c=, h=)\n",
    "        self.rnn_last_outputs = self.rnn_last_states[-1][1]\n",
    "        \n",
    "        self.logits, self.fc_keep_prob = self.get_fc(\n",
    "            self.rnn_last_outputs, self.fc_sizes, def_label_dim, self.keep_prob)\n",
    "\n",
    "        self.preds = tf.nn.softmax(logits=self.logits)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        #self.saver = tf.train.Saver(\n",
    "        #    tf.get_collection(tf.GraphKeys.VARIABLES, scope='classifier'))\n",
    "    \n",
    "    def get_checkpoint_path(self):\n",
    "        return os.path.join(self.model_path, self.name)\n",
    "        \n",
    "    def save_graph(self, sess):\n",
    "        save_path = self.saver.save(sess, self.get_checkpoint_path())\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "    def __init__(self,\n",
    "            batch_size=FLAGS.batch_size,\n",
    "            time_steps=FLAGS.time_steps,\n",
    "            rnn_sizes=[int(s) for s in FLAGS.rnn_sizes.split(',')],\n",
    "            fc_sizes=[int(s) for s in FLAGS.fc_sizes.split(',')],\n",
    "            keep_prob=FLAGS.keep_prob,\n",
    "            model_path=FLAGS.model_path,\n",
    "            model_name=None):\n",
    "        '''\n",
    "        Initializer default vales use tf.app.flags\n",
    "        returns an object, whose main fields are tensorflow graph nodes.\n",
    "        \n",
    "        batch_size: int, Number of samples to process in parallel. \n",
    "        time_steps: int, Maximum number of time steps which the model use for backprop\n",
    "        rnn_sizes: [int, [int...]] Size of corresponding LSTM cell's hidden state\n",
    "        fc_sizes: [int, [int...]] Size of fc layers connected to the last LSTM cell's output\n",
    "        keep_prob: float, Probability of keeping a value in DROPOUT layers\n",
    "        model_path: str, path/to/model/dir\n",
    "        '''\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        self.rnn_sizes = rnn_sizes\n",
    "        self.fc_sizes = fc_sizes\n",
    "        self.def_keep_prob = keep_prob\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        self.build_graph()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class stackedLSTM(object):\n",
    "    '''\n",
    "    Classify continous time series, using stacked LSTM network.\n",
    "    classifier will return an object, whose main fields are tensorflow graph nodes.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def get_input(self, batch_size):\n",
    "        with tf.variable_scope('input'):\n",
    "            x = tf.placeholder(tf.float32, [batch_size, None, def_input_dim], name='X')\n",
    "            seq_len = tf.placeholder(tf.int16, [None], name='length')\n",
    "        return x, seq_len\n",
    "    \n",
    "    def get_rnn(self, x, seq_len, batch_size, rnn_sizes, keep_prob):\n",
    "        with tf.variable_scope('LSTM'):\n",
    "            rnn_tuple_state = []\n",
    "\n",
    "            for size in rnn_sizes:\n",
    "                shape = [2, batch_size, size]\n",
    "                ph = tf.placeholder(tf.float32, shape)\n",
    "                rnn_tuple_state.append(\n",
    "                    tf.contrib.rnn.LSTMStateTuple(ph[0], ph[1]))\n",
    "                \n",
    "            rnn_tuple_state = tuple(rnn_tuple_state)\n",
    "\n",
    "            cells = [tf.contrib.rnn.BasicLSTMCell(size) for size in rnn_sizes]\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            cells = [tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob) \n",
    "                     for cell in cells]\n",
    "            multi_cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "            \n",
    "            with tf.variable_scope('dynamic_wrapper'):\n",
    "                outputs, last_states = tf.nn.dynamic_rnn(\n",
    "                    initial_state=rnn_tuple_state,\n",
    "                    inputs=x, cell=multi_cell, \n",
    "                    sequence_length=seq_len)\n",
    "                zero_state = multi_cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "        return outputs, last_states, keep_prob, rnn_tuple_state, zero_state\n",
    "\n",
    "    def get_fc(self, in_node, fc_sizes, out_dim, keep_prob):\n",
    "        with tf.variable_scope('fully_connected'):\n",
    "            act_fn = tf.nn.relu\n",
    "            h = in_node\n",
    "            keep_prob = tf.placeholder_with_default(keep_prob, [], 'keep_prob')\n",
    "            for size in fc_sizes:\n",
    "                h = tf.contrib.layers.fully_connected(h, size, act_fn)\n",
    "                tf.nn.dropout(h, keep_prob)\n",
    "            preds = tf.contrib.layers.fully_connected(h, out_dim, None)\n",
    "        return preds, keep_prob\n",
    "    \n",
    "    def get_name(self):\n",
    "        rnn_sizes = [str(s) for s in self.rnn_sizes]\n",
    "        fc_sizes = [str(s) for s in self.fc_sizes]\n",
    "        name = 'rnn' + '-'.join(rnn_sizes) + '--fc' + '-'.join(fc_sizes)\n",
    "        name += '---' + time.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "        return name\n",
    "    \n",
    "    def build_graph(self, model_name=None):\n",
    "        # tf.reset_default_graph()\n",
    "        if not model_name:\n",
    "            model_name = self.get_name()\n",
    "        self.name = model_name\n",
    "        \n",
    "        \n",
    "        self.keep_prob = tf.placeholder_with_default(self.def_keep_prob, [], 'keep_prob')\n",
    "        \n",
    "        self.x, self.seq_len = self.get_input(self.batch_size)\n",
    "        \n",
    "        #with tf.variable_scope('classifier'):\n",
    "        \n",
    "        rnn = self.get_rnn(\n",
    "            self.x, self.seq_len, self.batch_size, self.rnn_sizes, self.keep_prob)\n",
    "        self.rnn_outputs, self.rnn_last_states, self.rnn_keep_prob = rnn[:3]\n",
    "        self.init_state, self.zero_state = rnn[3:]\n",
    "        \n",
    "        \n",
    "        # Last layer's tuple, second element: (c=, h=)\n",
    "        self.rnn_last_outputs = self.rnn_last_states[-1][1]\n",
    "        \n",
    "        self.logits, self.fc_keep_prob = self.get_fc(\n",
    "            self.rnn_last_outputs, self.fc_sizes, def_label_dim, self.keep_prob)\n",
    "\n",
    "        self.preds = tf.nn.softmax(logits=self.logits)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        #self.saver = tf.train.Saver(\n",
    "        #    tf.get_collection(tf.GraphKeys.VARIABLES, scope='classifier'))\n",
    "    \n",
    "    def get_checkpoint_path(self):\n",
    "        return os.path.join(self.model_path, self.name)\n",
    "        \n",
    "    def save_graph(self, sess):\n",
    "        save_path = self.saver.save(sess, self.get_checkpoint_path())\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "    def __init__(self,\n",
    "            batch_size=FLAGS.batch_size,\n",
    "            time_steps=FLAGS.time_steps,\n",
    "            rnn_sizes=[int(s) for s in FLAGS.rnn_sizes.split(',')],\n",
    "            fc_sizes=[int(s) for s in FLAGS.fc_sizes.split(',')],\n",
    "            keep_prob=FLAGS.keep_prob,\n",
    "            model_path=FLAGS.model_path,\n",
    "            model_name=None):\n",
    "        '''\n",
    "        Initializer default vales use tf.app.flags\n",
    "        returns an object, whose main fields are tensorflow graph nodes.\n",
    "        \n",
    "        batch_size: int, Number of samples to process in parallel. \n",
    "        time_steps: int, Maximum number of time steps which the model use for backprop\n",
    "        rnn_sizes: [int, [int...]] Size of corresponding LSTM cell's hidden state\n",
    "        fc_sizes: [int, [int...]] Size of fc layers connected to the last LSTM cell's output\n",
    "        keep_prob: float, Probability of keeping a value in DROPOUT layers\n",
    "        model_path: str, path/to/model/dir\n",
    "        '''\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.time_steps = time_steps\n",
    "        self.rnn_sizes = rnn_sizes\n",
    "        self.fc_sizes = fc_sizes\n",
    "        self.def_keep_prob = keep_prob\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        self.build_graph()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class desc_classifier(stackedLSTM):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "c = classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files: 08527   \n",
      "Reading successful!\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "feeder = data.batch_pool(c.batch_size)\n",
    "feed = next(feeder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    init_state = sess.run(c.zero_state)\n",
    "    test_res = c.preds.eval({c.x:feed[0], c.seq_len:feed[2], c.init_state:init_state})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24996625,  0.25581524,  0.24560982,  0.24860872],\n",
       "       [ 0.2266767 ,  0.26111713,  0.26294613,  0.24926001],\n",
       "       [ 0.2438509 ,  0.25396317,  0.25237432,  0.24981159],\n",
       "       [ 0.24516293,  0.25698993,  0.2495202 ,  0.24832699]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
