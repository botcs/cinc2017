{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.signal import filtfilt as scipy_filtfilt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Filt-Filt operation definition\n",
    "\n",
    "- FeedBack filter components `[M]`:   $A = a_0, a_1, a_2 \\dots a_M$, where $a_0 = 0$ by definition\n",
    "- FeedForward filter components`[N]`:   $B = b_0, b_1, b_2 \\dots b_N$\n",
    "\n",
    "```\n",
    "y(t) = x(t)*b(0) + x(t-1)*b(1) + x(t-2)*b(2) ... x(t-M)*b(N)\n",
    "                 - y(t-1)*a(1) - y(t-2)*a(2) ... y(t-N)*a(M)\n",
    "```\n",
    "\n",
    "$$\n",
    "y_t = \\sum_{i=0}^{N} x_{t-i} \\cdot b_{i} - \\sum_{i=1}^{M} y_{t-i} \\cdot a_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "```\n",
    "y(t) = x[t-N : t] * b[::-1] - y[t-M : t-1] * a[::-1]\n",
    "```\n",
    "\n",
    "for faster computation let $s$ be $s := x \\ast b$, where $\\ast$ is the convolution operator, since all values of $x$ is known at computation time\n",
    "\n",
    "```\n",
    "y(t) = h[t] - y[y-t : t-1] * a[::-1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Final solution\n",
    "\n",
    "with tf loop... instead of queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In Part 2 the queue released 3 elements every time, but enqueued only 1 in return\n",
    "# Now for rapid rebuilding I put everythin into one cell\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "filter_size_upper_bound = 100\n",
    "CAPACITY = 300 * filter_size_upper_bound\n",
    "\n",
    "# [batch_size, sequnce_length]\n",
    "x = tf.placeholder(tf.float32, shape=[None, None], name='x_vector')\n",
    "\n",
    "# [filter_length(N/M), num_filters]\n",
    "a = tf.placeholder(tf.float32, shape=[15, 10], name='a_vector')\n",
    "b = tf.placeholder(tf.float32, shape=[20, 10], name='b_vector')\n",
    "\n",
    "batch_size = tf.shape(x)[0]\n",
    "sequence_length = tf.shape(x)[1]\n",
    "N = tf.shape(b)[0]\n",
    "M = tf.shape(a)[0]\n",
    "num_filters_a = tf.shape(a)[1]\n",
    "num_filters_b = tf.shape(b)[1]\n",
    "# filter_assert = tf.assert_equal(num_filters_a, num_filters_b)\n",
    "num_filters = num_filters_a\n",
    "'''y = tf.Variable([], trainable=False, validate_shape=False, name='y_vector')\n",
    "y_init = tf.zeros(dtype=tf.float32, \n",
    "                  shape=[sequence_length, batch_size, num_filters],\n",
    "                  name='y_zeros_init')\n",
    "y_init = tf.assign(y, y_init)\n",
    "'''\n",
    "\n",
    "y = tf.zeros(dtype=tf.float32, \n",
    "             shape=[batch_size, M, num_filters],\n",
    "             name='y_zeros_init')\n",
    "\n",
    "x_padded = tf.pad(x, [[0, 0], [N-1, 0]])\n",
    "\n",
    "s = tf.nn.conv1d(\n",
    "    value=x_padded[..., None], \n",
    "    filters=b[::-1, None, :], \n",
    "    stride=1, \n",
    "    padding='VALID',\n",
    "    name='s_vector')\n",
    "\n",
    "def prod(a, b, **kwargs):\n",
    "    return tf.reduce_sum(a * b, axis=1, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5, 4]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = list(range(10))\n",
    "\n",
    "i[-1:3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def body(y, s, a, t):\n",
    "    y_curr = s[:, t] - prod(y[:, t:(t+M)], [a], name='curr_y')\n",
    "    y = tf.concat([y, y_curr[:, None, :]], axis=1, name='y')\n",
    "    \n",
    "    t += 1\n",
    "    return y, s, a, t\n",
    "\n",
    "def cond(y, s, a, t):\n",
    "    return  t < sequence_length\n",
    "\n",
    "\n",
    "wl = tf.while_loop(cond, body, [y, s, a, 0], parallel_iterations=1, back_prop=False)\n",
    "filt = tf.pad(wl[0][:, -1:M-1:-1], [[0, 0], [M, 0], [0, 0]])\n",
    "wl = tf.while_loop(cond, body, [filt, s, a, 0], parallel_iterations=1, back_prop=False)\n",
    "filtfilt = wl[0][:, -1:M-1:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 400, 10)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.global_variables_initializer().run()\n",
    "test_feed = {\n",
    "    x: np.random.randn(100, 200),\n",
    "    a: np.random.randn(15, 10)*.001,\n",
    "    b: np.random.randn(20, 10)*.001\n",
    "}\n",
    "res = sess.run(filtfilt, test_feed)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Note: \n",
    "\n",
    "## The following are my attempts, which started with a lot of misunderstanding, but with progress everything cleared out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def resetSession():\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = resetSession()\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, shape=[None], name='x_vector')\n",
    "\n",
    "# Feedback filter\n",
    "a = tf.placeholder(tf.float32, shape=[None], name='a_vector')\n",
    "# Feedforward filter\n",
    "b = tf.placeholder(tf.float32, shape=[None], name='b_vector')\n",
    "\n",
    "N = tf.shape(b)[0]\n",
    "M = tf.shape(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Support vector\n",
    "# Default convolution works like this\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    a  b  c  d  e    ]\n",
    "#            +\n",
    "#         result\n",
    "\n",
    "# But this time we need the rightmost value as a result\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    a  b  c  d  e    ]\n",
    "#                  +\n",
    "#               result\n",
    "#\n",
    "# So we use padding like a Jedi, and use VALID convolution\n",
    "\n",
    "x_padded = tf.pad(x, [[N-1, 0]])\n",
    "\n",
    "# value[None, :, None] stands for [Batch, Sample, Channels]\n",
    "# In the basic example Batch = Channel = 1\n",
    "# filters[::-1, None, None] stands for [Filter_size(inverted), In_size, Out_size]\n",
    "# In the basic example In_size = Out_size = 1\n",
    "s = tf.nn.conv1d(value=x_padded[None, :, None], filters=b[::-1, None, None], stride=1, padding='VALID')\n",
    "s = tf.squeeze(s, name='s_vector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  2.,  3.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Watch out, the filter is now inverted\n",
    "x_test = list(range(1,7))\n",
    "b_test = [0, 0, 0, 1]\n",
    "s.eval({x:x_test, b:b_test})\n",
    "\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    e  d  c  b  a   ]\n",
    "#                  +\n",
    "#               result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b_test = [1, 0, 0]\n",
    "s.eval({x:x_test, b:b_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PART 2\n",
    "\n",
    "## The Support vector $s$\n",
    "\n",
    "Last cell in this part has some problems, will be rewrited in Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Output\n",
    "# Y values can be evaluated one-by-one, so as soon as we evaluate the t^th value\n",
    "# We push it to the back of the queue, and we always take as many values\n",
    "# as long is the Feedback filter vector is, for efficiently calculating inner product\n",
    "\n",
    "# Capacity is the upper bound of the size of the filter, \n",
    "# Since the queue needs to be able to dequeue filter sized vectors at once.\n",
    "\n",
    "filter_size_upper_bound = 100\n",
    "CAPACITY = 3 * filter_size_upper_bound\n",
    "# Since we could enqueue multiple tensors we use \n",
    "# listed `shapes` and `dtypes` but that is only for syntax autofellatio\n",
    "# Basically we will enqueue and dequeue scalar values (shape=[], dtype=tf.float32)\n",
    "y_queue = tf.FIFOQueue(CAPACITY, dtypes=[tf.float32], shapes=[[]], name='y_fifo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TF QUEUE mechanism demonstration\n",
    "\n",
    "**Supplementary reading [TF guide on queues](https://www.tensorflow.org/programmers_guide/threading_and_queues)**\n",
    "\n",
    "![demo](https://www.tensorflow.org/images/IncremeterFifoQueue.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We initialize the queue with zeros to mimic padding\n",
    "init = y_queue.enqueue_many(tf.zeros([N]))\n",
    "# y_deq is technically y[t-M : t-1] \n",
    "# which will be used for the inner product operation\n",
    "y_deq = y_queue.dequeue_many(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(sess.run([init, y_deq], {b:b_test}))\n",
    "# The result is\n",
    "# [None, array([ 0.,  0.,  0.], dtype=float32)]\n",
    "# because evaluating the init operator does not return any value\n",
    "# and evaluating the y_prev just returns our initialized values\n",
    "# be careful! now the queue is empty again\n",
    "\n",
    "# TRY ME!\n",
    "# print(sess.run([y_queue.enqueue((1)), init, y_prev], {b:b_test}))\n",
    "# now the queue is not empty, one zero is still left in it\n",
    "# be careful! it remembers its state within a Session\n",
    "# print(sess.run([y_queue.enqueue((1)), init, y_prev], {b:b_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a single vector product... a bit too verbose\n",
    "print(sess.run(tf.reduce_sum(a * b), {a:[1, 2, 3], b:[1, 10, 100]}))\n",
    "# reduce it\n",
    "def prod(a, b, **kwargs):\n",
    "    return tf.reduce_sum(a * b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# evaluating y_1, using s_t with zero indexing is s[t-1]\n",
    "# Now we write by hand the first step, \n",
    "# but this is not necessary\n",
    "y_1 = s[0] - prod(y_deq, a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_test = list(range(1, 5))\n",
    "b_test = [1, 0, 0]\n",
    "a_test = [1, 0, 0]\n",
    "test_feed = {x:x_test, b:b_test, a:a_test}\n",
    "\n",
    "\n",
    "sess.run([init, s, y_deq, y_1], test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# now evaluate a few more y_t\n",
    "# and see that to do it by hand is very annoying\n",
    "y_1 = s[0] - prod(y_deq, a) \n",
    "enq1 = y_queue.enqueue(y_1)\n",
    "\n",
    "y_2 = s[1] - prod(y_deq, a)\n",
    "enq2 = y_queue.enqueue(y_2)\n",
    "\n",
    "y_3 = s[2] - prod(y_deq, a)\n",
    "enq3 = y_queue.enqueue(y_3)\n",
    "\n",
    "y_4 = s[3] - prod(y_deq, a)\n",
    "\n",
    "explicit_fetch_list = [\n",
    "    init,\n",
    "    enq1,\n",
    "    enq2,\n",
    "    enq3,\n",
    "    y_4,\n",
    "]\n",
    "sess.run(explicit_fetch_list, test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT NOTE!!!\n",
    "# The order of graph definition here is not relevant\n",
    "# These operations are not executed by calling the lines above\n",
    "# the evaluation order is determined in the _fetch_list\n",
    "# \n",
    "# fetch is the operation when you evaluate a tensor\n",
    "# fetch its value (in the form of a numpy array) \n",
    "# from the computational graph\n",
    "#\n",
    "# The python variables here can be represented as\n",
    "# C++ pointers... so here each operator is pointed by y_i\n",
    "#\n",
    "# If I wrote simply y instead\n",
    "# like this\n",
    "\n",
    "y = s[0] - prod(y_deq, a) \n",
    "enq1 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[1] - prod(y_deq, a)\n",
    "enq2 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[2] - prod(y_deq, a)\n",
    "enq3 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[3] - prod(y_deq, a)\n",
    "\n",
    "impl_fetch_list = [\n",
    "    y_deq,\n",
    "    init,\n",
    "    enq1,\n",
    "    enq2,\n",
    "    enq3,\n",
    "    y\n",
    "]\n",
    "\n",
    "# In this case y always points to the latest operation/tensor we defined\n",
    "# It is still working because enq1, enq2... are linked together with\n",
    "# different y_t tensors\n",
    "\n",
    "# In order to make the computation valid\n",
    "# We need to enqueue in the right order\n",
    "\n",
    "sess.run(impl_fetch_list, test_feed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 3\n",
    "\n",
    "**Correcting Part 2**\n",
    "\n",
    "Automatizing the operations, tensorflow CONTROLFLOW operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In Part 2 the queue released 3 elements every time, but enqueued only 1 in return\n",
    "# Now for rapid rebuilding I put everythin into one cell\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "filter_size_upper_bound = 100\n",
    "CAPACITY = 300 * filter_size_upper_bound\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None], name='x_vector')\n",
    "y = tf.placeholder(tf.float32, shape=[None], name='y_vector')\n",
    "#a = tf.placeholder(tf.float32, shape=[None], name='a_vector')\n",
    "#b = tf.placeholder(tf.float32, shape=[None], name='b_vector')\n",
    "\n",
    "a = tf.Variable([1., 0., 0.], trainable=False)\n",
    "b = tf.Variable([1., 0., 0.], trainable=False)\n",
    "\n",
    "\n",
    "N = tf.shape(b)[0]\n",
    "M = tf.shape(a)[0]\n",
    "\n",
    "x_padded = tf.pad(x, [[N-1, 0]])\n",
    "\n",
    "s = tf.nn.conv1d(value=x_padded[None, :, None], filters=b[::-1, None, None], stride=1, padding='VALID')\n",
    "s = tf.squeeze(s, name='s_vector')\n",
    "\n",
    "y_q = tf.FIFOQueue(CAPACITY, dtypes=[tf.float32], shapes=[[]], name='y_fifo')\n",
    "#init_zeros = tf.Print(tf.zeros([N]), [y_q.size()], message='ENQ - init - Nb of elements left in queue:')\n",
    "y_init = y_q.enqueue_many(tf.zeros([N]))\n",
    "y_deq = y_q.dequeue_many(N)\n",
    "#y_deq = tf.Print(y_deq, [y_q.size()], message='DEQ - Nb of elements left in queue:')\n",
    "\n",
    "\n",
    "test_feed = {\n",
    "    x:list(range(1,7)),\n",
    "    a:[1, 0, 0],\n",
    "    b:[1, 0, 0]\n",
    "}\n",
    "\n",
    "def prod(a, b, **kwargs):\n",
    "    return tf.reduce_sum(a * b, **kwargs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# now evaluate a few more y_t\n",
    "# and see that to do it by hand is very annoying\n",
    "y_1 = s[0] - prod(y_deq, a)\n",
    "y_1 = tf.Print(y_1, [y_q.size()], message='ENQ - y1 - Nb of elements left in queue:')\n",
    "enq1 = y_q.enqueue(y_1)\n",
    "\n",
    "y_2 = s[1] - prod(y_deq, a)\n",
    "y_2 = tf.Print(y_2, [y_q.size()], message='ENQ - y2 - Nb of elements left in queue:')\n",
    "enq2 = y_q.enqueue(y_2)\n",
    "\n",
    "y_3 = s[2] - prod(y_deq, a)\n",
    "y_3 = tf.Print(y_2, [y_q.size()], message='ENQ - y3 - Nb of elements left in queue:')\n",
    "enq3 = y_q.enqueue(y_3)\n",
    "\n",
    "y_4 = s[3] - prod(y_deq, a)\n",
    "\n",
    "explicit_fetch_list = [\n",
    "    y_init,\n",
    "    enq1,\n",
    "    enq2,\n",
    "    enq3,\n",
    "    y_4,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# IMPORTANT\n",
    "\n",
    "Cells below are behaving differently"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Runs but the order is messed up, because y_deq is evaluated only once, \n",
    "# and its value is shared between the y_t operations\n",
    "sess.run(explicit_fetch_list, test_feed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# in this case y_deq is evaluated as expected\n",
    "\n",
    "# be careeful if queue goes empty and a thread is still \n",
    "# waiting for dequeue than the script will hang forever\n",
    "for op in impl_fetch_list:\n",
    "    print(sess.run(op, test_feed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clearing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# it seems that \"float\" can be used as well...\n",
    "s_q = tf.FIFOQueue(25000, 'float', shapes=[[]], name='support_fifo')\n",
    "# We don't want to slice each time we evaluate y\n",
    "# So we push the whole support vector into the queue\n",
    "# If running in parallel then he capacity can be exceeded while enqueueing\n",
    "# Capacity is about the maximum number of elements actually in the queue\n",
    "# hanging enqueues will activate when the q is dequeued\n",
    "\n",
    "s_init = s_q.enqueue_many(s)\n",
    "s_deq = s_q.dequeue()\n",
    "# s_deq = tf.Print(s_deq, [s_deq, s_q.size()], message='DEQ - s_deq | s_q.size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# actual evaluation\n",
    "y_curr = s_deq - prod(y_deq, a)\n",
    "#y_curr = tf.Print(y_curr, [y_curr, y_q.size()], message='DEQ - y_curr | y_q.size')\n",
    "# we need to feed back the last M-1 values\n",
    "# shifting the window, dropping the oldest values\n",
    "# which is the rightmost, lowest index\n",
    "y_prev = y_deq[1:]\n",
    "y_feedback = tf.concat([y_prev, [y_curr]], axis=0, name='y_feedback')\n",
    "#y_feedback = tf.Print(y_feedback, [y_feedback], message='ENQ - y_feedback')\n",
    "y_feedback = y_q.enqueue_many(y_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create an op that groups multiple operations_\n",
    "\n",
    "When this op finishes, all ops in input have finished. This op has no output.\n",
    "'''\n",
    "init = tf.group(y_init, s_init, name='init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "init.run({x:np.random.randn(10000)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bbc23c9ed6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0ms_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d\\r'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_feedback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3727\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3729\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while s_q.size().eval() > 0:\n",
    "    if i% 100 == 0: print('%d\\r'%i, end='', flush=True)\n",
    "    i += 1\n",
    "    y_feedback.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "print('-----')\n",
    "sess.run([init, y_feedback], test_feed)\n",
    "sess.run([y_feedback], test_feed)\n",
    "sess.run([y_feedback], test_feed)\n",
    "sess.run([y_curr, y_feedback], test_feed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The result of the Prints can be observed in the terminal\n",
    "\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - s_deq | s_q.size[1][0]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - y_curr | y_q.size[1][0]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] ENQ - y_feedback[0 0 1]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - s_deq | s_q.size[2][4]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - y_curr | y_q.size[2][3]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] ENQ - y_feedback[0 1 2]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - s_deq | s_q.size[3][4]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - y_curr | y_q.size[3][3]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] ENQ - y_feedback[1 2 3]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - s_deq | s_q.size[4][3]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] DEQ - y_curr | y_q.size[3][3]\n",
    "I tensorflow/core/kernels/logging_ops_cc:79] ENQ - y_feedback[2 3 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#y = tf.Variable([0.]*3, trainable=False, name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Final solution\n",
    "\n",
    "with tf loop... instead of queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# In Part 2 the queue released 3 elements every time, but enqueued only 1 in return\n",
    "# Now for rapid rebuilding I put everythin into one cell\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "filter_size_upper_bound = 100\n",
    "CAPACITY = 300 * filter_size_upper_bound\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None], name='x_vector')\n",
    "y = tf.placeholder(tf.float32, shape=[None], name='y_vector')\n",
    "t = tf.placeholder_with_default(0, shape=[], name='time')\n",
    "a = tf.placeholder(tf.float32, shape=[None], name='a_vector')\n",
    "b = tf.placeholder(tf.float32, shape=[None], name='b_vector')\n",
    "\n",
    "#a = tf.Variable([1., 0., 0.], trainable=False)\n",
    "#b = tf.Variable([1., 0., 0.], trainable=False)\n",
    "\n",
    "\n",
    "N = tf.shape(b)[0]\n",
    "M = tf.shape(a)[0]\n",
    "\n",
    "x_padded = tf.pad(x, [[N-1, 0]])\n",
    "\n",
    "s = tf.nn.conv1d(value=x_padded[None, :, None], filters=b[::-1, None, None], stride=1, padding='VALID')\n",
    "s = tf.squeeze(s, name='s_vector')\n",
    "\n",
    "\n",
    "\n",
    "def prod(a, b, **kwargs):\n",
    "    return tf.reduce_sum(a * b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def body(s, y, a, t):\n",
    "    y_curr = s[t] - prod(y, a)\n",
    "    y_prev = y[1:]\n",
    "    y = tf.concat([y_prev, [y_curr]], axis=0, name='y_feedback')\n",
    "    #y = tf.Print(y, [y, t], message='ENQ - y_feedback || t')\n",
    "    t += 1\n",
    "    return s, y, a, t\n",
    "\n",
    "def cond(s, y, a, t):\n",
    "    return  t < tf.shape(x)[0]\n",
    "\n",
    "\n",
    "wl = tf.while_loop(cond, body, [s, y, a, t], parallel_iterations=1, back_prop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#tf.global_variables_initializer().run()\n",
    "test_feed = {\n",
    "    x: np.random.randn(20000),\n",
    "    y: [0]*10,\n",
    "    a: np.eye(10)[0],\n",
    "    b: np.eye(10)[0]\n",
    "}\n",
    "res = sess.run([wl], test_feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
