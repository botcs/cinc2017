{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filt-Filt operation definition\n",
    "\n",
    "- FeedBack filter components `[M]`:   $A = a_0, a_1, a_2 \\dots a_M$, where $a_0 = 0$ by definition\n",
    "- FeedForward filter components`[N]`:   $B = b_0, b_1, b_2 \\dots b_N$\n",
    "\n",
    "```\n",
    "y(t) = x(t)*b(0) + x(t-1)*b(1) + x(t-2)*b(2) ... x(t-M)*b(N)\n",
    "                 - y(t-1)*a(1) - y(t-2)*a(2) ... y(t-N)*a(M)\n",
    "```\n",
    "\n",
    "$$\n",
    "y_t = \\sum_{i=0}^{N} x_{t-i} \\cdot b_{i} - \\sum_{i=1}^{M} y_{t-i} \\cdot a_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "```\n",
    "y(t) = x[t-N : t] * b[::-1] - y[t-M : t-1] * a[::-1]\n",
    "```\n",
    "\n",
    "for faster computation let $s$ be $s := x \\ast b$, where $\\ast$ is the convolution operator, since all values of $x$ is known at computation time\n",
    "\n",
    "```\n",
    "y(t) = h[t] - y[y-t : t-1] * a[::-1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resetSession():\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = resetSession()\n",
    "# Input\n",
    "x = tf.placeholder(tf.float32, shape=[None], name='x_vector')\n",
    "\n",
    "# Feedback filter\n",
    "a = tf.placeholder(tf.float32, shape=[None], name='a_vector')\n",
    "# Feedforward filter\n",
    "b = tf.placeholder(tf.float32, shape=[None], name='b_vector')\n",
    "\n",
    "# Support vector\n",
    "# Default convolution works like this\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    a  b  c  d  e    ]\n",
    "#            +\n",
    "#         result\n",
    "\n",
    "# But this time we need the rightmost value as a result\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    a  b  c  d  e    ]\n",
    "#                  +\n",
    "#               result\n",
    "#\n",
    "# So we use padding like a Jedi, and use VALID convolution\n",
    "x_padded = tf.pad(x, [[tf.shape(b)[0]-1, 0]])\n",
    "\n",
    "# value[None, :, None] stands for [Batch, Sample, Channels]\n",
    "# In the basic example Batch = Channel = 1\n",
    "# filters[::-1, None, None] stands for [Filter_size(inverted), In_size, Out_size]\n",
    "# In the basic example In_size = Out_size = 1\n",
    "s = tf.nn.conv1d(value=x_padded[None, :, None], filters=b[::-1, None, None], stride=1, padding='VALID')\n",
    "s = tf.squeeze(s, name='s_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  2.,  3.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = list(range(1, 5))\n",
    "b_test = [0, 1, 0]\n",
    "\n",
    "x_padded.eval({b:b_test, x:x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.eval({x:x_test, b:b_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Watch out, the filter is now inverted\n",
    "b_test = [0, 0, 1]\n",
    "s.eval({x:x_test, b:b_test})\n",
    "\n",
    "# [... 1  2  3  4  5...]\n",
    "#      *  *  *  *  *\n",
    "# [    e  d  c  b  a   ]\n",
    "#                  +\n",
    "#               result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test = [1, 0, 0]\n",
    "s.eval({x:x_test, b:b_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "# Y values can be evaluated one-by-one, so as soon as we evaluate the t^th value\n",
    "# We push it to the back of the queue, and we always take as many values\n",
    "# as long is the Feedback filter vector is, for efficiently calculating inner product\n",
    "\n",
    "# Capacity is the upper bound of the size of the filter, \n",
    "# Since the queue needs to be able to dequeue filter sized vectors at once.\n",
    "\n",
    "filter_size_upper_bound = 100\n",
    "CAPACITY = 3 * filter_size_upper_bound\n",
    "# Since we could enqueue multiple tensors we use \n",
    "# listed `shapes` and `dtypes` but that is only for syntax autofellatio\n",
    "# Basically we will enqueue and dequeue scalar values (shape=[], dtype=tf.float32)\n",
    "y_queue = tf.FIFOQueue(CAPACITY, dtypes=[tf.float32], shapes=[[]], name='y_fifo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF QUEUE mechanism demonstration\n",
    "\n",
    "**Supplementary reading [TF guide on queues](https://www.tensorflow.org/programmers_guide/threading_and_queues)**\n",
    "\n",
    "![demo](https://www.tensorflow.org/images/IncremeterFifoQueue.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We initialize the queue with zeros to mimic padding\n",
    "init = y_queue.enqueue_many((tf.zeros(tf.shape(b))))\n",
    "\n",
    "# y_deq is technically y[t-M : t-1] \n",
    "# which will be used for the inner product operation\n",
    "y_deq = y_queue.dequeue_many(tf.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, array([ 0.,  0.,  0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([init, y_deq], {b:b_test}))\n",
    "# The result is\n",
    "# [None, array([ 0.,  0.,  0.], dtype=float32)]\n",
    "# because evaluating the init operator does not return any value\n",
    "# and evaluating the y_prev just returns our initialized values\n",
    "# be careful! now the queue is empty again\n",
    "\n",
    "# TRY ME!\n",
    "# print(sess.run([y_queue.enqueue((1)), init, y_prev], {b:b_test}))\n",
    "# now the queue is not empty, one zero is still left in it\n",
    "# be careful! it remembers its state within a Session\n",
    "# print(sess.run([y_queue.enqueue((1)), init, y_prev], {b:b_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321.0\n"
     ]
    }
   ],
   "source": [
    "# a single vector product... a bit too verbose\n",
    "print(sess.run(tf.reduce_sum(a * b), {a:[1, 2, 3], b:[1, 10, 100]}))\n",
    "# reduce it\n",
    "def prod(a, b, **kwargs):\n",
    "    return tf.reduce_sum(a * b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating y_1, using s_t with zero indexing is s[t-1]\n",
    "# Now we write by hand the first step, \n",
    "# but this is not necessary\n",
    "y_1 = s[0] - prod(y_deq, a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " array([ 1.,  2.,  3.,  4.], dtype=float32),\n",
       " array([ 0.,  0.,  0.], dtype=float32),\n",
       " 1.0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = list(range(1, 5))\n",
    "b_test = [1, 0, 0]\n",
    "a_test = [1, 0, 0]\n",
    "test_feed = {x:x_test, b:b_test, a:a_test}\n",
    "\n",
    "sess.run([init, s, y_deq, y_1], test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1.0, None, 2.0, None, 3.0, None, 4.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now evaluate a few more y_t\n",
    "# and see that to do it by hand is very annoying\n",
    "y_1 = s[0] - prod(y_deq, a) \n",
    "enq1 = y_queue.enqueue(y_1)\n",
    "\n",
    "y_2 = s[1] - prod(y_deq, a)\n",
    "enq2 = y_queue.enqueue(y_2)\n",
    "\n",
    "y_3 = s[2] - prod(y_deq, a)\n",
    "enq3 = y_queue.enqueue(y_3)\n",
    "\n",
    "y_4 = s[3] - prod(y_deq, a)\n",
    "\n",
    "explicit_fetch_list = [\n",
    "    init,\n",
    "    y_1,\n",
    "    enq1,\n",
    "    y_2,\n",
    "    enq2,\n",
    "    y_3,\n",
    "    enq3,\n",
    "    y_4,\n",
    "]\n",
    "sess.run(explicit_fetch_list, test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  0.,  0.], dtype=float32), None, None, None, None, 4.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT NOTE!!!\n",
    "# The order of graph definition here is not relevant\n",
    "# These operations are not executed by calling the lines above\n",
    "# the evaluation order is determined in the _fetch_list\n",
    "# \n",
    "# fetch is the operation when you evaluate a tensor\n",
    "# fetch its value (in the form of a numpy array) \n",
    "# from the computational graph\n",
    "#\n",
    "# The python variables here can be represented as\n",
    "# C++ pointers... so here each operator is pointed by y_i\n",
    "#\n",
    "# If I wrote simply y instead\n",
    "# like this\n",
    "\n",
    "y = s[0] - prod(y_deq, a) \n",
    "enq1 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[1] - prod(y_deq, a)\n",
    "enq2 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[2] - prod(y_deq, a)\n",
    "enq3 = y_queue.enqueue(y)\n",
    "\n",
    "y = s[3] - prod(y_deq, a)\n",
    "\n",
    "impl_fetch_list = [\n",
    "    y_deq,\n",
    "    init,\n",
    "    enq1,\n",
    "    enq2,\n",
    "    enq3,\n",
    "    y\n",
    "]\n",
    "\n",
    "# In this case y always points to the latest operation/tensor we defined\n",
    "# It is still working because enq1, enq2... are linked together with\n",
    "# different y_t tensors\n",
    "\n",
    "# In order to make the computation valid\n",
    "# We need to enqueue in the right order\n",
    "\n",
    "# The first operator ensures that the list is empty\n",
    "sess.run(impl_fetch_list, test_feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
